# Using getafix {#getafix}

<http://research.smp.uq.edu.au/computing/getafix.html>

## Getafix structure

![](img/getafix_rendered.png)

### Cluster

Getafix is a cluster. That means there are many computers all talking to each-other and sharing resources.

The cluster will assign your job to nodes using the SLURM program.

### Node

Each computer in the cluster is called a node. Each node has it's own cpu's, memory and graphics card. Nodes all share a common network drive, so all your data is available on all the nodes.

### Cores and memory

Most nodes in Getafix have about 24 cores, a few have more and a few have less. Each node also typically has about 250GB of memory.

If I can find a list of the nodes, I'll add it for reference.

### Login Node

One node is special, the login node. Strictly speaking, Getafix is the login node, which is why Dogmatix, the older SMP cluster, has access to most of the same resources and nodes. The login node works like any remote computer, you can run jobs on the login node, but out of respect for other users, you should only do setup operations and short tests on the login node.

### SLURM

SLURM is the program that balances all the jobs between users across the cluster. You specify what you want the cluster to do, and how much time, nodes, cpu's and memory you think you will need. SLURM then waits until the cluster has enough resources available to run your job and starts the job. If you try to use more resources than you asked for, your job will be killed. If you ask for lots of resources, it might take a while for enough nodes to be available, since smaller jobs will usually fill up the available resources as other jobs end.

### Other Resources

The cluster has access to shared resources, particularly shared storage and networking, so your data is available on all the nodes at the same location.

## Getting into Getafix

### Request Access

Email ITS at help@its.uq.edu.au and request access to the SMP cluster which is called Getafix.

This can take a few days. Make sure you explain your connection to the School of Maths and Physics. For HDR students, you will often have both a staff and student account. Let ITS know which one you want to use to log in with.

### Network Access

You must be on the UQ intranet to access the servers.

### eduroam/uq cable/uq wifi

You are already in the intranet.

#### Everywhere else

You will need to install the UQ VPN software and log in. Follow the instructions at:

<https://my.uq.edu.au/information-and-services/information-technology/working-remotely/vpn-virtual-private-network>

### The terminal

To access Getafix, you will need a terminal program on your computer.

On mac, this is Terminal.

On windows, this is Command Prompt or Windows Powershell (not Windows Powershell ISE). If you don't have an up to date Windows 10 machine, install [PuTTy](https://www.chiark.greenend.org.uk/~sgtatham/putty/).

Some people like the Ubuntu app in windows 10, just remember the *mnt/c* syntax to get to the files on your computer.

### Logging into Getafix

Once you have your terminal open, type:

```{r eval=FALSE, engine='bash'}
ssh  <username>@getafix.smp.uq.edu.au
```

Where `<username>` is your staff or student login.

If a popup appears saying `"Authenticity can't be established"`. Say yes.

Enter your password.

If you see:
```{r, eval=FALSE, engine='bash'}
> ssh: Could not resolve hostname getafix.smp.uq.edu.au: This is usually 
> a temporary error during hostname resolution and means that the local
> server did not receive a response from an authoritative server.
```

Then you either typed it incorrectly or are not on the UQ internal network, see *Network Access*.

If you really want R X11 plots to appear on your desktop, add `-X` to the login. This works on Mac and Linux. Windows may need an X11 server, which you can most easily get from the Ubuntu app. I strongly recommend
saving plots into files and copying them to your computer, X11 can be very slow to render.

```{r, eval=FALSE, engine='bash'}
ssh -X <username>@getafix.smp.uq.edu.au
```

#### Advanced

1.  SSH config file

    `\~/.ssh/config`:

    ```{r, eval=FALSE, engine='bash'}
    Host my-getafix
      ForwardX11Trusted yes #equivalent to adding -X
      User uqpdyer
      HostName 130.102.3.59

    Host dogmatix
      ForwardX11Trusted yes
      User uqpdyer
      HostName dogmatix.smp.uq.edu.au

    ```

    Now, you only have to type

    ```{r, eval=FALSE, engine='bash'}
    ssh my-getafix
    ```

### Putting your data on Getafix

You need to have your data on Getafix. Where to put it?

```{r eval=FALSE}
ls /
```

#### Home

```{r eval=FALSE}
/home/username/
```

Which is often shortened to

```{r eval=FALSE}
~/
```

You have 40GB of data allowed in here.

The home directory is often used for programs and configuration files. R
libraries will install here by default, which is fine.

Don't use the home directory for data sets, results and plots.

#### Data

```{r eval=FALSE}
/data/username/
```

You have 400GB of data allowed in here.

Put your data sets and scripts in the `/data/username/` directory.

At some point we may have a shared folder in here, probably
`/data/mathmarecol/`.

#### Data1, Data2 â€¦ Data6

Most of the time you use `/data/` but there are other data folders that
you can access on request.

```{r eval=FALSE}
/data1/username/
/data2/username/
```

`data1` and `data2` are older system drives that we are not using.

`data3` to `data6` are high speed access drives for very large file
reading and writing. These could be useful for work on GCM's.

### Sending your data to getafix

#### scp

scp is copy over ssh, it should work anywhere ssh works.

```{r, eval=FALSE, engine='bash'}
scp -r  local_folder <username>@getafix.smp.uq.edu.au:/data/<username>/<folder>
```

#### WinSCP

A graphical interface for scp.

#### rsync

Rsync is smarter than scp, it only copies changes, so it can be faster
than scp.

usually installed on Linux, may not be available on Mac or Windows.

```{r, eval=FALSE, engine='bash'}
rsync  local_folder <username>@getafix.smp.uq.edu.au:/data/<username>/<folder>
```

## Running jobs on Getafix

### Modules

To allow different versions of software to be used by different users (like python 3.4 versus python 3.6), Getafix uses Linux modules. On Getafix, R is in a module, and won't work until you load the module. You
can use the default version of a module, or specify a particular version of a module if your job depends on it. 

To see what modules are available, type:

```{r, eval=FALSE, engine='bash'}
module avail
```

When you see a module you want to use, load it with:

```{r, eval=FALSE, engine='bash'}
module load <module name>
```

I use the following modules:

```{r, eval=FALSE, engine='bash'}
module load R
module load pandoc #rendering rmarkdown into html and pdf
module load gdal #spatial packages like sf
module load geos #spatial packages like sf
module load proj #spatial packages like sf
```

### R on Getafix

R on Getafix is pretty similar to R on your local computer, without RStudio.
#
### installing packages

Install packages to a local library in your home directory.

```{r, eval=FALSE, engine='bash'}
module load R
R
```

```{r, eval=FALSE}
install.packages("foreach")
install.packages("doParallel")
install.packages("sf")
```

Accept the default library location unless you have a reason not to.

If your package fails to install, check if there is a system package missing.

For example, to install `sf`, you need to load more modules:

```{r, eval=FALSE, engine='bash'}
module load R
module load gdal
module load geos
module load proj
R
```

Now `sf` should install.

```{r, eval=FALSE}
install.packages("sf")
```

If it still does not work, send an email to help@its.uq.edu.au, they have been helpful setting me up when something was missing or broken.

### Parameters for Rmd files

You can pass parameters into Rmd files from the command line. You need to set up the \`params\` in the YAML header, see
<https://bookdown.org/yihui/rmarkdown/parameterized-reports.html>

Using Rscript, you can render a report using a specified set of parameters like this:

```{r, eval=FALSE, engine='bash'}
paramlist='list(nCores =24, gRange = 1:300 )'
Rscript -e 'knitr::opts_knit$set(progress = TRUE, verbose = TRUE); rmarkdown::render("/data/uqpdyer/demo.Rmd", params = '"${paramlist}"', output_format = "html_notebook", output_file = "outfile.html", output_dir = "/data/uqpdyer", envir = new.env())'
```

This is not as convenient as setting parameters in RStudio or within an R session. You have to be very careful about quotes, and the command line is hard to edit.

Sending parameters to an R script in bulk is much easier, but lacks the reproducability of Rmd.

#### Parameters for script files

Use the base `commandArgs` or the `optparse` package to use command line parameters in your script files

Then you can run the script from the command line like this:

```{r, eval=FALSE, engine='bash'}
Rscript script.R input1 input2
```

### SLURM

So far, R has been running on the login node. Some things are easiest to do on the login node, like installing packages and transferring files. Computationally heavy tasks should be done on other nodes. To use the other nodes, you submit jobs with SLURM.

SLURM is a job scheduler. People request jobs by specifying the resources they need and the scripts to run, and SLURM queues the jobs until some nodes are available to run the job. You can also request an
interactive session, but it is more efficient to set up jobs and come back to get the results.

#### `sbatch`

The command `sbatch` is used to submit jobs, which are run when the resources become available.

You use SLURM by calling `sbatch`:

```{r, eval=FALSE, engine='bash'}
sbatch script.sh
```

where `script.sh` looks like

```{r, eval=FALSE, engine='bash'}
#!/bin/bash
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=1G
#SBATCH --time=0-00:10

echo "hello world"
```

The `#SBATCH` lines at the top are parameters for the sbatch command, you can also include them in the command call:

```{r, eval=FALSE, engine='bash'}
sbatch script.sh --ntasks=1 --cpus-per-task=1 --mem-per-cpu=1G --time=0-00:10 script.sh
```

Then `script.sh` can simplify down to:

```{r, eval=FALSE, engine='bash'}
#!/bin/bash

echo "hello world"
```

When working with R, we run scripts or arbitrary code snippets with Rscript, but the `sbatch` command still expects Rscript to be wrapped in `script_for_r.sh`

``` shell
#!/bin/bash
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=20
#SBATCH --mem-per-cpu=2G
#SBATCH --time=0-01:00

module load R
Rscript myRscript.R
```

So running `sbatch` looks the same:

```{r, eval=FALSE, engine='bash'}
sbatch script_for_r.sh
```

Here is a meaningful r script we can test out. Note that I have specified 20 cpu's in both `script_for_r.sh` and `myRscript.R`

```{r, eval=FALSE}
library(foreach)
library(doParallel)

cl <- makeCluster(2)
registerDoParallel(cl)
x <- iris[which(iris[,5] != "setosa"), c(1,5)]
trials <- 10000

ptime <- system.time({
  r <- ~foreach~(icount(trials), .combine=cbind) %dopar% {
    ind <- sample(100, 100, replace=TRUE)
    result1 <- glm(x[ind,2]~x[ind,1], family=binomial(logit))
    coefficients(result1)
  }
})[3]
ptime


stime <- system.time({
  r <- ~foreach~(icount(trials), .combine=cbind) %do% {
    ind <- sample(100, 100, replace=TRUE)
    result1 <- glm(x[ind,2]~x[ind,1], family=binomial(logit))
    coefficients(result1)
  }
})[3]
stime

stopCluster(cl)

cl <- makeCluster(20)
registerDoParallel(cl)
ptime <- system.time({
  r <- ~foreach~(icount(trials), .combine=cbind) %dopar% {
    ind <- sample(100, 100, replace=TRUE)
    result1 <- glm(x[ind,2]~x[ind,1], family=binomial(logit))
    coefficients(result1)
  }
})[3]
ptime

```

#### `salloc` and `srun`

If you really need to run something interactively, such as a Matlab GUI, make sure you log in with `-X` or `-Y` and then call:

``` 1
salloc --ntasks=1 --cpus-per-task=1 --mem-per-cpu=1G --time=0-00:10
srun --pty -x11 matlab
```

#### Many nodes

So far, we have used only 1 node. The memory and cpu's are all in the same node, and R behaves in exactly the same way as on your machine, only with more cores. You are clearly limited to a speed up of around 20 times with a single node.

To go beyond the single node limit, you have a few options.

1.  Divide your job up

- If you can break your job up into many independent runs, then you can submit a job for each run, and collect all the different outputs after all the jobs have run.
- I have done this to test out the effects of changing combinations of parameters.

2.  Rslurm

- The Rslurm package will generate a set of scripts that submit a collection of jobs. Rslurm does the work of dividing up your job for you.
- Take care with this package, the default settings will allocate far too many jobs and overwhelm Getafix.

##### The `rslurm` package #####

###### Submitting a job with rslurm ######

Package `rslurm` allows you to produce the files to run a parallel job on a SLURM queue and extract the results. The basic syntax to produce the submission files is below.  

```
slr_job <- slurm_apply(f, params, jobname = NA, nodes = 1, cpus_per_node = 1,add_objects = NULL, pkgs = rev(.packages()), libPaths = NULL,slurm_options = list(), submit = TRUE)
```

* `f` is a function containing code you want to run. It should take one or many single values as parameters, and may return any type of R object.

* `params` is a data frame of parameter values to apply `f` to. Each column corresponds to a parameter of `f` (note that the names must agree) and each row corresponds to a separate function call.

* `jobname` is the name of the Slurm job. If this is set to `NA`, the job name is "slr#####, where #### is 4 random digits.

* `nodes` is the (maximum) number of cluster nodes to be used. `slurm_apply` automatically divides the rows of `params` into chunks of approximately equal size. Fewer nodes are allocated if the parameter set is too small to use all CPUs on the requested nodes.

* `cpus_per_node` determines how many processes will be run in parallel on each node.

* `add_objects` is a character vector containing the names of R objects to be saved in a .RData file and loaded on each node prior to calling `f`.

* `pkgs` is a character vector containing the names of packages that must be loaded on each node. Default behaviour is to use all packages loaded when you call `slurm_apply`.

* `libPaths` is a character vector with the locations of additional R library trees to search through. If `NULL`, it only looks in the libraries returned by `.libPaths()` on the node. Non-existent libraries are silently ignored.

* `slurm options` is a list of options recognised by SLURM's `sbatch`. Note that the "array", "job-name", "nodes" and "output" are determined by `slurm_apply`, so don't specify them here.

  + `time` is the time limit on each job, in the format `D-HH:MM`.

  + `mem-per-cpu` is the memory to be allocated to each cpu being used.

  + `ntasks` refers to the number of tasks in each job. This is **not** the total number of tasks. Usually this will be the default value of 1.

  + `cpus-per-task` sets the number of cpus to be allocated per process. Default is 1.

  + Other options can be found in the `sbatch` [documentation](https://slurm.schedmd.com/sbatch.html). Note that the full option names must be used (for example, `time` rather than `t`).

* `submit` determines whether or not the job is sent ot the cluster. If `submit = TRUE`, the job is sent to the cluster and either a confirmation or error message is output to the console. When `submit = FALSE`, a message indicates the location of the saved data and script files and you can submit the job manually by running `sbatch submit.sh` from that directory.

###### Read the output ######

The results will be saved as a collection of files `results_#.RDS`, one file for each cluster node used. The `get_slurm_out` reads all these files and returns the result as a single data frame or list.

```
func_result <- get_slurm_out(slr_job, outtype = "raw", wait = TRUE)
```

Here, `slr_job` is a SLURM job (the output of a `slurm_apply` or `slurm_job` command), `outtype` specifies whether the output should be a list (`outtype="raw"`) or data frame (`outtype="table"`) and `wait` specifies whether or not the command should be blocked until `slr_job` is complete.

`slr_job` is automatically created when `slurm_apply` is called, but if you change R session you may need to manually recreate it to use `get_slurm_out`. Use the following code to do so, using the same `jobname` and number of `nodes` as the submitted job.

```
slr_job <- slurm_job(jobname, nodes)
```

###### Other rslurm commands ######

If running R on the cluster, you can use the following commands to check on the status of a running job (or the console and error output generated, if any, of a completed one), or cancel a running job. 

```
print_job_status(slr_job)
cancel_slurm(slr_job)
```

Once the results have been collected with `get_slurm_out`, you can use `cleanup_files(slr_job)` to delete the temporary files and raw outputs from the cluster.

To run a single function evaluation on the cluster, you can use `slurm_call` in place of `slurm_apply`:

```
slr_job <- slurm_call(f, params, jobname = NA, add_objects = NULL,pkgs = rev(.packages()), libPaths = NULL, slurm_options = list(),submit = TRUE)
```

###### Issues ######

* The submit.sh file that rslurm ouputs by default doesn't work on the cluster. To fix this, the authors of the package recommend editing the template file. Go to your R library (use `.libPaths()` in the console to find out where this is) and then to the rslurm/templates/submit_sh.txt. Replace line 12 with

```
module load R
R CMD BATCH slurm_run.R
```

* For large arrays (more than ~150 tasks), you should be limiting the number of jobs being requested at one time, but this isn't possible if you submit directly from R with `submit=TRUE` in `slurm_apply`. Make sure you submit your job array manually to set the right array (i.e. `sbatch --array=0-<max_node>%100 submit.sh` to limit to 100 tasks.)

* If you generate the submission files in Windows, it may not play nicely with the cluster (which expects a *NIX-formatted bash script). Run `dos2unix submit.sh` first to convert submit.sh to the correct formatting.

###### Accounting with `sacct` ######

It can be hard to know in advance what the memory and time requirements of a given job are, and it can take some trial-and-error. My recommendation is to run the first time with "plenty" of resources (e.g. multiply your best esimate by two) then use the actual usage to determine what you need in future trials.

You can type `sacct -j <jobid> --format=JobID,JobName,MaxRSS,Elapsed` into the terminal to find out the maximum memory usage and elapsed time of a particular job. If you don't know the jobid, use `--starttime YYYY-MM-DD` and `--endtime YYYY-MM-DD` to show all jobs run between two dates. For more options, see the `sacct` [documentation](https://slurm.schedmd.com/sacct.html).

3.  MPI
- Message Passing Interface (MPI) is a library that shares information across nodes.
- MPI requires extra setup in your code, and you need to use `mpirun` or `srun` inside the sbatch script

```{r, eval=FALSE, engine='bash'}
    #!/bin/bash
    #SBATCH --ntasks=1
    #SBATCH --cpus-per-task=1
    #SBATCH --mem-per-cpu=1G
    #SBATCH --time=0-00:10

    mpirun echo "running with MPI"
    srun echo "run with SRUN"
```

doMPI and Rmpi are packages for working with MPI in R.

TODO: I have not figured out MPI on the cluster yet, it didn't "just work"

4.  future.batchTools
- The future.batchtools package lets you submit SLURM jobs from R. The benefit of using future.batchtools is that you write R code using future syntax, then specify a SLURM plan, and all futures at a level specified by the plan are sent off as jobs. The script waits until the job finishes.
- I recommend running a single node task with 1 cpu and a modest amount of ram, but a long running time, then all the heavy lifting is done by new jobs submitted by your script.
- Take care with this package, I haven't checked the defaults, but it might request too many resources like Rslurm.

#### R with parameters

Being able to pass in parameters is useful for dividing your job up.

Some examples of sbatch scripts that use R parameters

```{r, eval=FALSE, engine='bash'}
#!/bin/bash
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=24
#SBATCH --mem-per-cpu=7G
#SBATCH --time=1-22:00
module load R
Rscript script.R $1 $2
```

```{r, eval=FALSE, engine='bash'}
    sbatch run_script.sh input1 input2
    sbatch run_script.sh input1 input3
```

`$1` becomes the first argument, `input1` both times, and `$2` becomes
the second argument, `input2` in the first run and `input3` in the
second line.

Rendering an Rmd file with parameters:

```{r, eval=FALSE, engine='bash'}
#!/bin/bash
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=24
#SBATCH --mem-per-cpu=7G
#SBATCH --time=1-22:00
module load R
module load pandoc #essential for knitr and rmarkdown

paramlist='list(nCores =24, gRange = 1:300 )'
Rscript -e 'knitr::opts_knit$set(progress = TRUE, verbose = TRUE); rmarkdown::render("/data/uqpdyer/demo.Rmd", params = '"${paramlist}"', output_format = "html_notebook", output_file = "outfile.html", output_dir = "/data/uqpdyer", envir = new.env())'

```

If you want to generate a collection of rendered Rmd files, you have to
write up a script for each set of parameters.

The other way to generate a set of Rmd files with different parameters,
in parallel, is to copy the file and change the parameters in each file.
Then you can use job arrays by naming the files from 1 to n.

The simplest approach I can think of to run many different Rmd files is
to have a shell script, that calls an R script, that renders an Rmd.
Parameters passed to the shell script go all the way down to the Rmd
file.

```{r, eval=FALSE}
args = commandArgs(trailingOnly = TRUE)

knitr::opts_knit$set(progress = TRUE, verbose = TRUE)

paramlist=list(nCores =as.numeric(args[1]), gRange = as.numeric(args[2]):as.numeric(args[3]))
rmarkdown::render("/data/uqpdyer/demo.Rmd", params = paramlist, output_format = "html_notebook",
                  output_file = "outfile.html", output_dir = "/data/uqpdyer", envir = new.env())
```
## Debugging Rmd files

Debugging regular R isn't great, but debugging Rmd files non-interactively is even worse.

Here are some tricks:

### Cache on

Turn on caching for your Rmd file.

```{r caching_on}
knitr::opts_chunk$set(cache=TRUE)
```

### Load in cache dir

The qwraps2 package on github has a function, `lazyload_cache`, which will pull in the saved cache so you can interact with it in RStudio.

<https://github.com/dewittpe/qwraps2/blob/master/R/lazyload_cache.R>

Once you call `lazyload_cache()` on the cache generated by knitr, your environment has all the variables seen up until a failure point.

## Getting Results back

The batch jobs are not interactive. You set them up to run and come back for the results. Usually you save a file to disk.

### Printed text

All printed output goes to a file `slurm-<job number>.out`.

You can change the name with

```{r, eval=FALSE, engine='bash'}
#!/bin/bash
#SBATCH -o output_file_%A_%a.out #%A is the job number, %a is the array number
#SBATCH -e error_file.err
```

### Data.frames

If you have R objects you want to see, save them to disk.

  - saveRDS
    R binary format, single object, you specify the name when you readRDS
  - fwrite
    data.table csv writer, fast, and gives you a csv
  - feather
    a new binary format backed by Hadley, fast, and compatible with
    python
  - fst
    another new binary format, extremely fast and you can read in
    subsets of the data.frame
  - Archivist
    puts everything into a database and gives a unique hash to every
    object. Good for reproducibility, you can't mix up objects from
    different runs later on because the hash always changes

### Plots

Always save plots to disk, unless you are using Rmd files, which will
put the plot into the output html anyway.

Use `ggsave()` for ggplots, and `dev.png()`, your plotting code, `dev.off()` for other kinds of R plots.

It is a good idea to set the width, height and dpi for all your plots.

## Playing nice

The cluster is a shared resource.

Try to be as precise as possible when allocating resources, so others can use what you don't need.

Be careful with any package that submits jobs for you (`Rslurm`,`future.batchtools`). Check the jobs are requesting a reasonable set of resources.

### Parallel coding in R

#### parlapply, par*apply etc.

The parallel package gives you par\* versions of the apply family of functions.

Easy to drop in if you usually use the apply family from base R, you replace any `apply`, `lapply`, `sapply` with `parapply`, `parlapply`, `parsapply`.

#### foreach and %dopar%

The `foreach` package has a few uses.

First, it changes how you use `for` loops in R. Base R `for` loops usually work by changing a variable defined outside the loop. `foreach` is more like an `apply`, where a result is returned, so `foreach` works without needing to use side effects.

Second, because `foreach` can work without side effects, it can run the loop in parallel easily. There are a number of backends you can use, including `doParallel`, `doMPI`, `doFuture`. You can quickly change how parallel works by replacing `%do%` with `%dopar%` and changing the registerDo\* function at the start of your script.

If you already like using `foreach` over the apply family, moving to parallel is easy. The main downside is that `foreach` is not particularly efficient with resources. If you are mostly using the apply family, switching to `foreach` is much harder.

#### `future`

The `future` package is built around the idea of a promise. The promise is "Eventually the variable will have a result assigned to it, but not straight away". You replace `<-` with `%<-%` and the line of code becomes a promise, rather than something to do right away.

Generally, you don't need to change your code much, just add `%` around your `<-` at strategic points, but you can gain a lot of flexibility, and there are many backends.

`future.apply` gives you parallel versions of `apply`. `doFuture` mixes `future` and `foreach`.

`future.batchtools` spawns jobs on the cluster that return the results into your session. `future.callr` does local parallel calculations in separate R processes. `future` alone will do local multiprocessor calculations and use multiple nodes.

#### General Coding habits for going parallel

1. Put things into lists
- It is easy to loop over lists, and you can quickly parallelise the processing of a list.

2. Don't do graphics in parallel
- Generally speaking, you can specify ggplot objects in parallel, but if you try to print or save them in parallel, R crashes.
- You probably have to work very carefully to open multiple `dev.png()` for plotting base R plots.

3. Make functions small
- If you repeat something frequently, put it into a function. You can then put functions into packages. Try to keep functions small, then they are easier to use in parallel. Generally don't try to work in parallel within a function.
- If you want a function to use parallel processing, I strongly recommend you use either `future` or `foreach` with `%dopar%`. By default, they both drop back to sequential processing, but the user can set up parallel processing before calling the function to get speed improvements.

4. Look for loops, but don't use R base `for` loops
- Base R `for` loops cannot be used in parallel, because they rely on side effects.

## Tricks

1. Don't forget which computer you are looking at
