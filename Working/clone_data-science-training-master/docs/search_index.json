[
["index.html", "Introduction to Open Data Science Chapter 1 Welcome", " Introduction to Open Data Science The Ocean Health Index Team 2019-06-19 Chapter 1 Welcome This training book will introduce you to open data science so you can work with data in an open, reproducible, and collaborative way. Open data science means that methods, data, and code are available so that others can access, reuse, and build from it without much fuss. Here you will learn a workflow with R, RStudio, Git, and GitHub, as we describe in Lowndes et al. 2017, Nature Ecology &amp; Evolution: Our path to better science in less time using open data science tools. This is going to be fun, because learning these open data science tools and practices is empowering! This training book is written (and always improving) so you can use it as self-paced learning, or it can be used to teach an in-person workshop where the instructor live-codes. Either way, you should do everything hands-on on your own computer as you learn. Before you begin, be sure you are all set up: see the prerequisites in Chapter 2. Suggested breakdown for a 2-day workshop: time Day 1 Day 2 9-10:30 Motivation, R &amp; RStudio, Rmarkdown Data Wrangling: tidyr break 11-12:30 GitHub Programming lunch 13:30-15:00 Visualization: ggplot2 Collaborating with GitHub break 15:30-17:00 Data Wrangling: dplyr Practice, Be a champion for open data science This book has been used in the following: Open Data Science Training — 2 day workshop at the University of Queensland, Australia 2019-06-18 Software Carpentry — 2-day workshop at the Woods Hole Oceanographic Institution (WHOI) 2018-10-22 Data integration and team science — 4 day workshop at NCEAS, California, USA 2018-03-12 Data Carpentry — 2-day workshop at the University of California Merced 2017-08-17 Software Carpentry — 2-day workshop at the Monterey Bay Aquarium Research Institute (MBARI) 2017-11-30 Software Carpentry: Reproducible Science with RStudio and GitHub — 2-day workshop at Oxford University 2016-07-12 Software Carpentry — 2-day workshop at UC Santa Barbara 2016-04-15 "],
["overview.html", "Chapter 2 Overview 2.1 What to expect 2.2 What you’ll learn 2.3 Learning with data that are not your own 2.4 Emphasizing collaboration 2.5 By the end of the course… 2.6 Prerequisites 2.7 Credit", " Chapter 2 Overview Welcome. In this training you will learn R, RStudio, Git, and GitHub. It’s going to be fun and empowering! You will learn a reproducible workflow that can be used in research and analyses of all kinds, including Ocean Health Index assessments. This is really powerful, cool stuff, and not just for data: I made and published this book using those four tools and workflow. We will practice learning three main things all at the same time: coding with best practices (R/RStudio), collaborative version control (Git/GitHub), and communication/publishing (RMarkdown/GitHub). This training will teach these all together to reinforce skills and best practices, and get you comfortable with a workflow that you can use in your own projects. 2.1 What to expect This is going to be a fun workshop. The plan is to expose you to a lot of great tools that you can have confidence using in your research. You’ll be working hands-on and doing the same things on your own computer as we do live on up on the screen. We’re going to go through a lot in these two days and it’s less important that you remember it all. More importantly, you’ll have experience with it and confidence that you can do it. The main thing to take away is that there are good ways to approach your analyses; we will teach you to expect that so you can find what you need and use it! A theme throughout is that tools exist and are being developed by real, and extraordinarily nice, people to meet you where you are and help you do what you need to do. If you expect and appreciate that, you will be more efficient in doing your awesome science. You are all welcome here, please be respectful of one another. You are encouraged to help each other. Everyone in this workshop is coming from a different place with different experiences and expectations. But everyone will learn something new here, because there is so much innovation in the data science world. Instructors and helpers learn something new every time, from each other and from your questions. If you are already familiar with some of this material, focus on how we teach, and how you might teach it to others. Use these workshop materials not only as a reference in the future but also for talking points so you can communicate the importance of these tools to your communities. A big part of this training is not only for you to learn these skills, but for you to also teach others and increase the value and practice of open data science in science as a whole. 2.2 What you’ll learn how to THINK about data how to think about data separately from your research questions how and why to tidy data and analyze tidy data, rather than making your analyses accommodate messy data how there is a lot of decision-making involved with data analysis, and a lot of creativity how to increase efficiency in your science and increase reproducibility and facilitate collaboration with others — especially Future You! how open science is a great benefit find solutions faster broaden the impact of your work how to learn with intention and community think ahead instead of only to get a single job done now the #rstats online community is fantastic. The tools we’re using are developed by real people. Real, nice people. They are building powerful and empowering tools and are welcoming to all skill-levels 2.2.1 Tidy data workflow We will be learning about tidy data. And how to use a tidyverse suite of tools to work with tidy data. Hadley Wickham and his team have developed a ton of the tools we’ll use today. Here’s an overview of techniques to be covered in Hadley Wickham and Garrett Grolemund of RStudio’s book R for Data Science: We will be focusing on: Tidy: tidyr to organize rows of data into unique values Transform: dplyr to manipulate/wrangle data based on subsetting by rows or columns, sorting and joining Visualize: ggplot2 static plots, using grammar of graphics principles Communicate dynamic documents with R Markdown This is really critical. Instead of building your analyses around whatever (likely weird) format your data are in, take deliberate steps to make your data tidy. When your data are tidy, you can use a growing assortment of powerful analytical and visualization tools instead of inventing home-grown ways to accommodate your data. This will save you time since you aren’t reinventing the wheel, and will make your work more clear and understandable to your collaborators (most importantly, Future You). 2.3 Learning with data that are not your own One of the most important things you will learn is how to think about data separately from your own research context. Said in another way, you’ll learn to distinguish your data questions from your research questions. Here, we are focusing on data questions, and we will use data that is not specific to your research. We will be using several different data sets throughout this training, and will help you see the patterns and parallels to your own data, which will ultimately help you in your research. 2.4 Emphasizing collaboration Collaborating efficiently has historically been really hard to do. It’s only been the last 20 years or so that we’ve moved beyond mailing things with the postal service. Being able to email and get feedback on files through track changes was a huge step forward, but it comes with a lot of bookkeeping and reproduciblity issues (did I do my analyses with thesis_final_final.xls or thesis_final_usethisone.xls?). But now, open tools make it much easier to collaborate. Working with collaborators in mind is critical for reproducibility. And, your most important collaborator is Future You. This training will introduce best practices using open tools, so that collaboration will become second nature to you! 2.5 By the end of the course… By the end of the course, you’ll wrangle a few different data sets, and make your own graphics that you’ll publish on webpages you’ve built collaboratively with GitHub and RMarkdown. Woop! Here are some important things to keep in mind as you learn (these are joke book covers): 2.6 Prerequisites Before the training, please make sure you have done the following: Download and install up-to-date versions of: R: https://cloud.r-project.org RStudio: http://www.rstudio.com/download Git: https://git-scm.com/downloads Note: open the download and follow normal install procedures on your computer but you won’t see any software installed when you’re done Create a GitHub account: https://github.com Note! Shorter names that kind of identify you are better, and use your work email! Get comfortable: if you’re not in a physical workshop, be set up with two screens if possible. You will be following along in RStudio on your own computer while also watching a virtual training or following this tutorial on your own. 2.7 Credit This material builds from a lot of fantastic materials developed by others in the open data science community. In particular, it pulls from the following resources, which are highly recommended for further learning and as resources later on. Specific lessons will also cite more resources. R for Data Science by Hadley Wickham and Garrett Grolemund STAT 545 by Jenny Bryan Happy Git with R by Jenny Bryan Software Carpentry by the Carpentries "],
["rstudio.html", "Chapter 3 R &amp; RStudio, RMarkdown 3.1 Objectives &amp; Resources 3.2 Why learn R with RStudio 3.3 R at the console, RStudio goodies 3.4 Your Turn 3.5 R functions, help pages 3.6 Packages 3.7 Clearing the environment 3.8 RMarkdown 3.9 RMarkdown video (1-minute) 3.10 Troubleshooting", " Chapter 3 R &amp; RStudio, RMarkdown 3.1 Objectives &amp; Resources 3.1.1 Objectives In this lesson we will: get oriented to the RStudio interface work with R in the console be introduced to built-in R functions learn to use the help pages explore RMarkdown 3.1.2 Resources This lesson is a combination of excellent lessons by others (thank you Jenny Bryan and Data Carpentry!) that I have combined and modified for our workshop today. I definitely recommend reading through the original lessons and using them as reference: Dr. Jenny Bryan’s lectures from STAT545 at UBC R basics, workspace and working directory, RStudio projects Basic care and feeding of data in R RStudio has great resources about its IDE (IDE stands for integrated development environment): webinars cheatsheets 3.1.3 Data and packages We will be using data and packages that are installed with R (often called “Base R”). 3.2 Why learn R with RStudio You are all here today to learn how to code. Coding made me a better scientist because I was able to think more clearly about analyses, and become more efficient in doing so. Data scientists are creating tools that make coding more intuitive for new coders like us, and there is a wealth of awesome instruction and resources available to learn more and get help. Here is an analogy to start us off. Think of yourself as a pilot, and R is your airplane. You can use R to go places! With practice you’ll gain skills and confidence; you can fly further distances and get through tricky situations. You will become an awesome pilot and can fly your plane anywhere. And if R were an airplane, RStudio is the airport. RStudio provides support! Runways, communication, community, and other services that makes your life as a pilot much easier. So it’s not only the infrastructure (the user interface or IDE), although it is a great way to learn and interact with your variables, files, and interact directly with GitHub. It’s also a data science philosophy, R packages, community, and more. So although you can fly your plane without an airport and we could learn R without RStudio, that’s not what we’re going to do. We are learning R together with RStudio and its many supporting features. Something else to start us off is to mention that you are learning a new language here. It’s an ongoing process, it takes time, you’ll make mistakes, it can be frustrating, but it will be overwhelmingly awesome in the long run. We all speak at least one language; it’s a similar process, really. And no matter how fluent you are, you’ll always be learning, you’ll be trying things in new contexts, learning words that mean the same as others, etc, just like everybody else. And just like any form of communication, there will be miscommunications that can be frustrating, but hands down we are all better off because of it. While language is a familiar concept, programming languages are in a different context from spoken languages, but you will get to know this context with time. For example: you have a concept that there is a first meal of the day, and there is a name for that: in English it’s “breakfast”. So if you’re learning Spanish, you could expect there is a word for this concept of a first meal. (And you’d be right: ‘desayuno’). We will get you to expect that programming languages also have words (called functions in R) for concepts as well. You’ll soon expect that there is a way to order values numerically. Or alphabetically. Or search for patterns in text. Or calculate the median. Or reorganize columns to rows. Or subset exactly what you want. We will get you increase your expectations and learn to ask and find what you’re looking for. 3.3 R at the console, RStudio goodies Launch RStudio/R. Notice the default panes: Console (entire left) Environment/History (tabbed in upper right) Files/Plots/Packages/Help (tabbed in lower right) FYI: you can change the default location of the panes, among many other things: Customizing RStudio. An important first question: where are we? If you’ve have opened RStudio for the first time, you’ll be in your Home directory. This is noted by the ~/ at the top of the console. You can see too that the Files pane in the lower right shows what is in the Home directory where you are. You can navigate around within that Files pane and explore, but note that you won’t change where you are: even as you click through you’ll still be Home: ~/. OK let’s go into the Console, where we interact with the live R process. Make an assignment and then inspect the object you created by typing its name on its own. x &lt;- 3 * 4 x ## [1] 12 In my head I hear, e.g., “x gets 12”. All R statements where you create objects – “assignments” – have this form: objectName &lt;- value. I’ll write it in the console with a hashtag #, which is the way R comments so it won’t be evaluated. ## objectName &lt;- value ## This is also how you write notes in your code to explain what you are doing. Object names cannot start with a digit and cannot contain certain other characters such as a comma or a space. You will be wise to adopt a convention for demarcating words in names. # i_use_snake_case # other.people.use.periods # evenOthersUseCamelCase Make an assignment this_is_a_really_long_name &lt;- 2.5 To inspect this variable, instead of typing it, we can press the up arrow key and call your command history, with the most recent commands first. Let’s do that, and then delete the assignment: this_is_a_really_long_name ## [1] 2.5 Another way to inspect this variable is to begin typing this_…and RStudio will automagically have suggested completions for you that you can select by hitting the tab key, then press return. One more: science_rocks &lt;- &quot;yes it does!&quot; You can see that we can assign an object to be a word, not a number. In R, this is called a “string”, and R knows it’s a word and not a number because it has quotes &quot; &quot;. You can work with strings in your data in R pretty easily, thanks to the stringr and tidytext packages. We won’t talk about strings very much specifically, but know that R can handle text, and it can work with text and numbers together (this is a huge benefit of using R). Let’s try to inspect: sciencerocks # Error: object &#39;sciencerocks&#39; not found 3.3.1 Error messages are your friends Implicit contract with the computer / scripting language: Computer will do tedious computation for you. In return, you will be completely precise in your instructions. Typos matter. Case matters. Pay attention to how you type. Remember that this is a language, not unsimilar to English! There are times you aren’t understood – it’s going to happen. There are different ways this can happen. Sometimes you’ll get an error. This is like someone saying ‘What?’ or ‘Pardon’? Error messages can also be more useful, like when they say ‘I didn’t understand what you said, I was expecting you to say blah’. That is a great type of error message. Error messages are your friend. Google them (copy-and-paste!) to figure out what they mean. And also know that there are errors that can creep in more subtly, when you are giving information that is understood, but not in the way you meant. Like if I am telling a story about suspenders that my British friend hears but silently interprets in a very different way (true story). This can leave me thinking I’ve gotten something across that the listener (or R) might silently interpreted very differently. And as I continue telling my story you get more and more confused… Clear communication is critical when you code: write clean, well documented code and check your work as you go to minimize these circumstances! 3.3.2 Logical operators and expressions A moment about logical operators and expressions. We can ask questions about the objects we made. == means ‘is equal to’ != means ‘is not equal to’ &lt; means ` is less than’ &gt; means ` is greater than’ &lt;= means ` is less than or equal to’ &gt;= means ` is greater than or equal to’ x == 2 ## [1] FALSE x &lt;= 30 ## [1] TRUE x != 5 ## [1] TRUE Shortcuts You will make lots of assignments and the operator &lt;- is a pain to type. Don’t be lazy and use =, although it would work, because it will just sow confusion later. Instead, utilize RStudio’s keyboard shortcut: Alt + - (the minus sign). Notice that RStudio automagically surrounds &lt;- with spaces, which demonstrates a useful code formatting practice. Code is miserable to read on a good day. Give your eyes a break and use spaces. RStudio offers many handy keyboard shortcuts. Also, Alt+Shift+K brings up a keyboard shortcut reference card. My most common shortcuts include command-Z (undo), and combinations of arrow keys in combination with shift/option/command (moving quickly up, down, sideways, with or without highlighting. When assigning a value to an object, R does not print anything. You can force R to print the value by using parentheses or by typing the object name: weight_kg &lt;- 55 # doesn&#39;t print anything (weight_kg &lt;- 55) # but putting parenthesis around the call prints the value of `weight_kg` ## [1] 55 weight_kg # and so does typing the name of the object ## [1] 55 Now that R has weight_kg in memory, we can do arithmetic with it. For instance, we may want to convert this weight into pounds (weight in pounds is 2.2 times the weight in kg): weight_kg * 2.2 ## [1] 121 We can also change a variable’s value by assigning it a new one: weight_kg &lt;- 57.5 weight_kg * 2.2 ## [1] 126.5 And when we multiply it by 2.2, the outcome is based on the value currently assigned to the variable. OK, let’s store the animal’s weight in pounds in a new variable, weight_lb: weight_lb &lt;- weight_kg * 2.2 and then change weight_kg to 100. weight_kg &lt;- 100 What do you think is the current content of the object weight_lb? 126.5 or 220? Why? It’s 125.6. Why? Because assigning a value to one variable does not change the values of other variables — if you want weight_kg updated to reflect the new value for weight_lb, you will have to re-execute that code. This is why we re-comment working in scripts and documents rather than the Console, and will introduce those concepts shortly and work there for the rest of the day. We can create a vector of multiple values using c(). c(weight_lb, weight_kg) ## [1] 126.5 100.0 names &lt;- c(&quot;Jamie&quot;, &quot;Melanie&quot;, &quot;Julie&quot;) names ## [1] &quot;Jamie&quot; &quot;Melanie&quot; &quot;Julie&quot; 3.4 Your Turn Exercise 1. Create a vector that contains the different weights of four fish (you pick the object name!): - one fish: 12 kg - two fish: 34 kg - red fish: 20 kg - blue fish: 6.6 kg 2. Convert the vector of kilos to pounds (hint: 1 kg = 2.2 pounds) 3. Calculate the total weight fish_weights &lt;- c(12, 34, 20, 6.6) fish_weights_lb &lt;- fish_weights * 2.2 sum(fish_weights_lb) #we haven&#39;t gone over functions like `sum()` yet but this is covered in the next section ## [1] 159.72 3.5 R functions, help pages R has a mind-blowing collection of built-in functions that are used with the same syntax: function name with parentheses around what the function needs to do what it is supposed to do. function_name(argument1 = value1, argument2 = value2, ...). When you see this syntax, we say we are “calling the function”. Let’s try using seq() which makes regular sequences of numbers and, while we’re at it, demo more helpful features of RStudio. Type se and hit TAB. A pop up shows you possible completions. Specify seq() by typing more to disambiguate or using the up/down arrows to select. Notice the floating tool-tip-type help that pops up, reminding you of a function’s arguments. If you want even more help, press F1 as directed to get the full documentation in the help tab of the lower right pane. Type the arguments 1, 10 and hit return. seq(1, 10) ## [1] 1 2 3 4 5 6 7 8 9 10 We could probably infer that the seq() function makes a sequence, but let’s learn for sure. Type (and you can autocomplete) and let’s explore the help page: ?seq help(seq) # same as ?seq The help page tells the name of the package in the top left, and broken down into sections: Description: An extended description of what the function does. Usage: The arguments of the function and their default values. Arguments: An explanation of the data each argument is expecting. Details: Any important details to be aware of. Value: The data the function returns. See Also: Any related functions you might find useful. Examples: Some examples for how to use the function. seq(from = 1, to = 10) # same as seq(1, 10); R assumes by position ## [1] 1 2 3 4 5 6 7 8 9 10 seq(from = 1, to = 10, by = 2) ## [1] 1 3 5 7 9 The above also demonstrates something about how R resolves function arguments. You can always specify in name = value form. But if you do not, R attempts to resolve by position. So above, it is assumed that we want a sequence from = 1 that goes to = 10. Since we didn’t specify step size, the default value of by in the function definition is used, which ends up being 1 in this case. For functions I call often, I might use this resolve by position for the first argument or maybe the first two. After that, I always use name = value. The examples from the help pages can be copy-pasted into the console for you to understand what’s going on. Remember we were talking about expecting there to be a function for something you want to do? Let’s try it. 3.5.1 Your turn Exercise: Talk to your neighbor(s) and look up the help file for a function that you know or expect to exist. Here are some ideas: ?getwd(), ?plot(), min(), max(), ?mean(), ?log()). And there’s also help for when you only sort of remember the function name: double-question mark: ??install Not all functions have (or require) arguments: date() ## [1] &quot;Wed Jun 19 08:44:44 2019&quot; 3.6 Packages So far we’ve been using a couple functions from base R, such as seq() and date(). But, one of the amazing things about R is that a vast user community is always creating new functions and packages that expand R’s capabilities. In R, the fundamental unit of shareable code is the package. A package bundles together code, data, documentation, and tests, and is easy to share with others. They increase the power of R by improving existing base R functionalities, or by adding new ones. The traditional place to download packages is from CRAN, the Comprehensive R Archive Network, which is where you downloaded R. You can also install packages from GitHub, which we’ll do tomorrow. You don’t need to go to CRAN’s website to install packages, this can be accomplished within R using the command install.packages(&quot;package-name-in-quotes&quot;). Let’s install a small, fun package praise. You need to use quotes around the package name.: install.packages(&quot;praise&quot;) Now we’ve installed the package, but we need to tell R that we are going to use the functions within the praise package. We do this by using the function library(). What’s the difference between a package and a library? Sometimes there is a confusion between a package and a library, and you can find people calling “libraries” to packages. Please don’t get confused: library() is the command used to load a package, and it refers to the place where the package is contained, usually a folder on your computer, while a package is the collection of functions bundled conveniently. library(praise) ## Error in library(praise): there is no package called &#39;praise&#39; Now that we’ve loaded the praise package, we can use the single function in the package, praise(), which returns a randomized praise to make you feel better. praise() ## Error in praise(): could not find function &quot;praise&quot; 3.7 Clearing the environment Now look at the objects in your environment (workspace) – in the upper right pane. The workspace is where user-defined objects accumulate. You can also get a listing of these objects with a few different R commands: objects() ## [1] &quot;fish_weights&quot; &quot;fish_weights_lb&quot; ## [3] &quot;names&quot; &quot;science_rocks&quot; ## [5] &quot;this_is_a_really_long_name&quot; &quot;weight_kg&quot; ## [7] &quot;weight_lb&quot; &quot;x&quot; ls() ## [1] &quot;fish_weights&quot; &quot;fish_weights_lb&quot; ## [3] &quot;names&quot; &quot;science_rocks&quot; ## [5] &quot;this_is_a_really_long_name&quot; &quot;weight_kg&quot; ## [7] &quot;weight_lb&quot; &quot;x&quot; If you want to remove the object named weight_kg, you can do this: rm(weight_kg) To remove everything: rm(list = ls()) or click the broom in RStudio’s Environment pane. For reproducibility, it is critical that you delete your objects and restart your R session frequently. You don’t want your whole analysis to only work in whatever way you’ve been working right now — you need it to work next week, after you upgrade your operating system, etc. Restarting your R session will help you identify and account for anything you need for your analysis. We will keep coming back to this theme but let’s restart our R session together: Go to the top menus: Session &gt; Restart R. 3.7.1 Your turn Exercise: Clear your workspace, then create a few new variables. Create a variable that is the mean of a sequence of 1-20. What’s a good name for your variable? Does it matter what your ‘by’ argument is? Why? 3.8 RMarkdown Now we are going to also introduce RMarkdown. This is really key for collaborative research, so we’re going to get started with it early and then use it for the rest of the day. This is also going to introduce us to the fact that RStudio is a sophisticated text editor (among all the other awesome things). You can use it to keep your files and scripts organized within one place (the RStudio IDE) while getting support that you expect from text editors (check-spelling and color, to name a few). An RMarkdown file will allow us to weave markdown text with chunks of R code to be evaluated and output content like tables and plots. File -&gt; New File -&gt; RMarkdown… -&gt; Document of output format HTML, OK. You can give it a Title like “My Project”. Then click OK. OK, first off: by opening a file, we are seeing the 4th pane of the RStudio console, which is essentially a text editor. This lets us organize our files within RStudio instead of having a bunch of different windows open. Let’s have a look at this file — it’s not blank; there is some initial text is already provided for you. Notice a few things about it: There are white and grey sections. R code is in grey sections, and other text is in white. Let’s go ahead and “Knit HTML” by clicking the blue yarn at the top of the RMarkdown file. What do you notice between the two? So much of learning to code is looking for patterns. Notice how the grey R code chunks are surrounded by 3 backticks and {r LABEL}. These are evaluated and return the output text in the case of summary(cars) and the output plot in the case of plot(pressure). Notice how the code plot(pressure) is not shown in the HTML output because of the R code chunk option echo=FALSE. The hashtag (#) at lines 12 and 22 cause the following text to be displayed larger and in bold. This RMarkdown file has 2 different languages within it: R and Markdown. We don’t know that much R yet, but you can see that we are taking a summary of some data called ‘cars’, and then plotting. We will focus on R for the rest of the workshop, but for the rest of this morning let’s focus on the second language. The second language is Markdown. This is a formatting language for plain text, and there are only about 15 rules to know. Notice the syntax for: headers get rendered at multiple levels: #, ## bold: **word** There are some good cheatsheets to get you started, and here is one built into RStudio: Go to Help &gt; Markdown Quick Reference Important: note that the hashtag # is used differently in Markdown and in R: in R, a hashtag indicates a comment that will not be evaluated. You can use as many as you want: # is equivalent to ######. It’s a matter of style. I use two ## to indicate a comment so that it’s clearer what is a comment versus what I don’t want to run at the moment. in Markdown, a hashtag indicates a level of a header. And the number you use matters: # is a “level one header”, meaning the biggest font and the top of the hierarchy. ### is a level three header, and will show up nested below the # and ## headers. If this seems confusing, take comfort in the fact that you are already used to using #s differently in real life: it can mean “number” or “pound” or hashtags on social media. Learn more: http://rmarkdown.rstudio.com/ 3.8.1 Your Turn In Markdown write some italic text, make a numbered list, and add a few subheaders. Use the Markdown Quick Reference (in the menu bar: Help &gt; Markdown Quick Reference). Reknit your html file. 3.8.2 Code chunks OK. Now let’s practice with some of those commands that we were working on this morning. Create a new chunk in your RMarkdown first in one of these ways: click “Insert &gt; R” at the top of the editor pane type by hand ```{r} ``` if you haven’t deleted a chunk that came with the new file, edit that one Now, let’s write some R code. x &lt;- seq(1:15) Now, hitting return does not execute this command; remember, it’s a text file in the text editor, it’s not associated with the R engine. To execute it, we need to get what we typed in the the R chunk (the grey R code) down into the console. How do we do it? There are several ways (let’s do each of them): copy-paste this line into the console. select the line (or simply put the cursor there), and click ‘Run’. This is available from the bar above the file (green arrow) the menu bar: Code &gt; Run Selected Line(s) keyboard shortcut: command-return click the green arrow at the right of the code chunk 3.8.3 Your turn Add a few more commands to your file from this morning. Execute them by trying the three ways above. Then, save your R Markdown file. 3.9 RMarkdown video (1-minute) Let’s watch this to demonstrate all the amazing things you can now do: What is RMarkdown? 3.10 Troubleshooting Here are some additional things we didn’t have time to discuss: 3.10.1 I entered a command and nothing’s happening It may be because you didn’t complete a command: is there a little + in your console? R is saying that it is waiting for you to finish. In the example below, I need to close that parenthesis. &gt; x &lt;- seq(1, 10 + 3.10.2 How do I update RStudio? To see if you have the most current version of RStudio, go to the Help bar &gt; Check for Updates. If there is an update available, you’ll have the option to Quit and Download, which will take you to http://www.rstudio.com/download. When you download and install, choose to replace the previous version. "],
["github.html", "Chapter 4 GitHub 4.1 Objectives 4.2 What are Git and Github? 4.3 Why should scientists use GitHub? 4.4 Resources 4.5 Let’s get started 4.6 Explore remote Github 4.7 Going back in time 4.8 Happy Git with R", " Chapter 4 GitHub 4.1 Objectives After today you will be able to start incorporating GitHub into your workflow. This will change you life (for the better!) Github was developed for social coding (i.e., sort of like an open source Wikipedia for programmers). Consequently, much of the functionality and terminology of Github (e.g., branches and pull requests) will not be relevant for most scientists. We will skip over all this stuff! To get the full functionality of Github, you will eventually want to learn other concepts. But, this can wait. Basically, we have figured out exactly what you need to know to get started! 4.2 What are Git and Github? Git and GitHub are two distinct programs, but I think of them as a bundle because I always use them together. Git is a version control system that lets you track changes to files over time. Github is a website for storing your git versioned files remotely. It has many nice features to be able visualize differences between images, rendering &amp; diffing map data files, render text data files, and track changes in text. 4.3 Why should scientists use GitHub? Ends (or, nearly ends) the horror of keeping track of versions. Basically, we get away from this: When you open your repository, you only see the most recent version. But, it easy to compare versions, and you can easily revert to previous versions. Provides peace of mind because you make changes to your work…and know that you can easily access earlier versions. Improves collaborative efforts. Different researchers can work on the same files at the same time! It is easy to share and distribute files through the Github website. Your files are available anywhere, you just need internet connection! We’ll interface with GitHub from our local computers using RStudio because it works well with the R/RStudio workflow. But, there are many other ways to interact with GitHub, including GitHub’s Desktop App or the command line (here is Jenny Bryan’s list of git clients). At some point you will need to use the command line to interface with Git, but this isn’t necessary for starting. There are great resources for learning the command line, check out this tutorial from SWC at UCSB. 4.4 Resources These are materials we borrow from: Jenny Bryan’s lectures from STAT545 at UBC: The Shell Jenny Bryan’s Happy git with R tutorial Melanie Frazier’s GitHub Quickstart Ben Best’s Software Carpentry at UCSB 4.5 Let’s get started 4.5.1 Some Github terminology User: A Github account for you (e.g., jules32). Organization: The Github account for one or more user (e.g., datacarpentry). Repository: A folder within the organization that includes files dedicated to a project. Local Github: Copies of Github files located your computer. Remote Github: Github files located on the https://github.com website. Clone: Process of making a local copy of a remote Github repository. This only needs to be done once (unless you mess up your local copy). Pull: Copy changes on the remote Github repository to your local Github repository. This is useful if multiple people are making changes to a repository. Push: Save local changes to remote Github After we set up git on your computers, we’ll explore the full GitHub process: create a repository on GitHub.com clone locally using RStudio learn the RStudio-GitHub workflow by syncing to Github.com: pull, stage, commit, push explore github.com: files, commit history, file history practice the RStudio-GitHub workflow by editing and adding files practice R Markdown 4.5.2 Setup Git &amp; GitHub The GitHub setup is a one-time thing! You will only have to do this once per computer. We’ll walk through this together. NOTE: If you are a student you can get the micro account which includes 5 private repositories for free (normally a $7/month value). You can sign up for the student account here. Instructors can also request a free organization account, “Request a discount”. Download and install Git (https://git-scm.com/downloads) Create a Github account at http://github.com, if you don’t already have one. For a username, I recommend all lower-case letters, short as you can. I recommend using your .edu email, since you can request free private repositories via GitHub Education discount. You will use the usethis package to configure git with global commands, which means it will apply ‘globally’ to all files on your computer, rather than to a specific folder. install.packages(&quot;usethis&quot;) library(usethis) use_git_config(user.name = &quot;Melsteroni&quot;, user.email = &quot;Melsteroni@example.org&quot;) BACKUP PLAN If usethis fails, the following is the classic approach to configuring git. Open the Git Bash program (Windows) or the Terminal (Mac) and type the following: # display your version of git git --version # replace USER with your Github user account git config --global user.name USER # replace NAME@EMAIL.EDU with the email you used to register with Github git config --global user.email NAME@EMAIL.EDU # list your config to confirm user.* variables set git config --list Make sure Git and RStudio are tallking: Click on “Project (None)” on the top right –&gt; “New Project” –&gt; “Version Control” –&gt; Git Do any ominous messages pop up? 4.5.2.1 Troubleshooting If you have problems setting up git, please see the Troubleshooting section in Jenny Bryan’s amazing HappyGitWithR. New(ish) Error on a Mac We’ve also seen the following errors from RStudio: error key does not contain a section --global terminal and fatal: not in a git directory To solve this, go to the Terminal and type: which git Look at the filepath that is returned. Does it say anything to do with Apple? -&gt; If yes, then the Git you downloaded isn’t installed, please redownload if necessary, and follow instructions to install. -&gt; If no, (in the example image, the filepath does not say anything with Apple) then proceed below: In RStudio, navigate to: Tools &gt; Global Options &gt; Git/SVN. Does the “Git executable” filepath match what the url in Terminal says? If not, click the browse button and navigate there. Note: on my laptop, even though I navigated to /usr/local/bin/git, it then automatically redirect because /usr/local/bin/git was an alias on my computer. That is fine. Click OK. Quit RStudio. Then relaunch RStudio. Try syncing or cloning, and if that works and then you don’t need to worry about typing into the Terminal, you’re all done! 4.5.3 Create a repository on Github.com First, go to your account on github.com and click “New repository”. Choose a name. Call it whatever you want (the shorter the better), or follow me for convenience. I will call mine quickstart. Also, add a description, make it public, create a README file, and create your repo! The Add gitignore option adds a document where you can identify files or file-types you want Github to ignore. These files will stay in on the local Github folder (the one on your computer), but will not be uploaded onto the web version of Github. The Add a license option adds a license that describes how other people can use your Github files (e.g., open source, but no one can profit from them, etc.). We won’t worry about this today. Check out our new repository! Notice how the README.md file we created is automatically displayed at the bottom. The .md means that it is Markdown (remember how .Rmd was RMarkdown?) so the formatting we learned in the last lesson apply here. From here, you will work locally (on your computer). 4.5.4 Clone your repository using RStudio We are going to be cloning a copy of our remote repository on Github.com to our local computers. Unlike downloading, cloning keeps all the version control and user information bundled with the files. Step 0: Create your github folder This is really important! We need to be organized and deliberate about where we want to keep all of our GitHub repositories (since this is the first of many in your career). Let’s all make a folder called github (all lowercase!) in our home directories. So it will look like this: Windows: Users\\[User]\\Documents\\github\\ Mac: Users/[User]/github/ This will let us take advantage of something that is really key about GitHub.com: cloned repositories are saved as folders that you can navigate on your computer. The greatness of this will be evident soon. So really. Make sure that you have an all-lowercase folder called github in your home directory!! Step 1: Copy the web address of the repository you want to clone. Step 2: from RStudio, go to New Project (also in the File menu). Step 3: Select Version Control Step 4: Select Git Step 5: Paste it in the Repository URL field, and type tab to autofill the Project Directory name. Make sure you keep the Project Directory Name THE SAME as the repository name from the URL. Save it in your github folder (click on Browse) to do this. 4.5.5 Inspect results If everything went well, the repository will be added to the list located here: when we cloned this from RStudio, it created an RStudio project, which you can tell because: - our working directory is set to `~/github/Quickstart` - there&#39;s an `.RProj` file in the &quot;Files&quot; tab - the project is named in the top right hand corner - we have a git tab! This is how we will interface with Github.com When you first clone a repo through RStudio, RStudio will add an .Rproj file to your repo folder. If you didn’t add a .gitignore file when you originally created the repo on GitHub.com, RStudio will also add this for you. These will show up with little yellow ? icons in your git tab. This is GitHub’s way of saying: “ooohh…..something changed in the repository”. In this case, when you click the box to stage them, they will turn into As because they have been added to the repo. And the repository will be saved to the Github folder on your computer: Ta da!!!! The folder doesn’t contain much of interest, but we are going to change that. 4.5.6 Add files to our local repo The repository will contain: .gitignore file README.md Rproj And, I typically create the following: folders for “data” and “figures” R scripts etc. We can use the Git tab of RStudio to monitor changes to files in the local repository. When files change, RStudio uses the following codes to describe how the files have been modified: We will demonstrate this by copying a file into the repository folder on my computer. This file will be added to the Git tab beside a green box with an “A”! From this, you can see how the repository is being tracked, even when changes aren’t made through RStudio. We can also make changes through RStudio! 4.5.7 Committing your changes and syncing with GitHub.com Eventually you will want to commit the files you have created in your local repository and then send them to GitHub.com I tend to do this every time I finish a task (basically when I start getting nervous that I will lose my work). Once something is committed, it is very difficult to lose it. Committing saves the current saved version of your files to the official Git History. The commit includes all the staged files as well as a corresponding commit message (which you will write) and a unique identifier called a SHA ID. When you are ready to commit your changes, follow these steps: We walk through this process below: 4.5.7.1 Pull From the Git tab, “Pull” the repository. This makes sure your local repository is synced with the remote repository. This is very important if other people are making changes to the repository or if you are working from multiple computers. 4.5.7.2 Stage Stage the files you want to commit. In RStudio, this involves checking the “Staged” boxes: 4.5.7.3 Commit Add a commit message that describes the updates you made to these files. The message will be for your reference, so make it something you will find useful. 4.5.7.4 Push You will “Push” to save your local changes to Github.com. 4.6 Explore remote Github The files you added should be on github.com: Your turn! This time let’s edit an existing file instead of adding something new. Open your README file by clicking on it in the Files pane (lower right corner). Write a few lines of text, save, and see what happens in your Git Tab. Sync it to your remote repository (Github.com). Also, go to your Finder/Windows Explorer, and copy-paste something into your local GitHub repo. Then go back to RStudio and confirm that git tracked it. Remember, git will track anything within that folder (the way Dropbox does), it’s not specific to RStudio! Create a new R Markdown file Now, we are going to return to using R Markdown so you can write notes to yourself in Markdown and have a record of all your R code. Writing R commands in the console like we did this morning is great, but limited; it’s hard to keep track of and hard to efficiently share with others. Plus, as your analyses get more complicated, it basically becomes impossible to use. Go to File &gt; New File &gt; R Markdown … (or click the green plus in the top left corner). Let’s set up this file so we can use it later. I’m going to replace all the automatic text with the following: --- title: &quot;Graphics with ggplot2&quot; author: &quot;Julie&quot; date: &quot;11/21/2017&quot; output: html_document --- # Learning ggplot2 We&#39;re learning ggplot2 It&#39;s going to be amazing. Now, let’s save it. I’m going to call my file ggplot2.Rmd. Then, sync your file to GitHub. What if a file doesn’t show up in the Git tab and you expect that it should? Check to make sure you’ve saved the file. If the filename is red with an asterix, there have been changes since it was saved. Remember to save before syncing to GitHub! 4.7 Going back in time One thing that I love about about Github is that it is easy to see how files have changed over time. Usually I compare commits through github.com: You can click on the commits to see how the files changed from the previous commit: 4.8 Happy Git with R If you have problems, we’ll help you out using Jenny Bryan’s HappyGitWithR, particularly the sections on Detect Git from RStudio and RStudio, Git, GitHub Hell (troubleshooting). So as we are coming around, have a look at it and see if you can help troubleshoot too! "],
["ggplot2.html", "Chapter 5 Visualizing: ggplot2 5.1 Why ggplot2? 5.2 Additional resources for data visualization in R 5.3 Objectives 5.4 Install tidyverse: tidyverse 5.5 Create an RMarkdown file to work from 5.6 Load the tidverse 5.7 Load and explore data 5.8 Plotting with ggplot2 5.9 Saving plots 5.10 Arranging plots 5.11 Interactive plots 5.12 Save and push to GitHub", " Chapter 5 Visualizing: ggplot2 5.1 Why ggplot2? This tutorial focuses exclusively on data visualization using ggplot2 because this package: provides a coherent language for visualizing data (vs. the original ‘plot’ function, which developed in an ad-hoc way) makes many tasks easier, such as: visualizing a third (z) variable; saving figures; automating plotting and formatting tasks creates beautiful figures and is flexible You should really use ggplot2 for nearly all data visualization! 5.2 Additional resources for data visualization in R The goal of this tutorial is to introduce you to the basics of ggplot2. I focus only on the features I use most often. We will barely scratch the surface of ggplot2’s functionality. But there are many resources that will help you learn more. Here are some of the ones I use: The official ggplot2 cheatsheet is amazing! Winston Chang’s book converted me from someone who was slightly confused by ggplot2 to a superuser….so I can’t recommend it enough! And, the associated website is great too. Hadley Wickham’s R for Data Science book, which is inspiration for much of this tutorial. 5.3 Objectives install the ggplot2 package by installing tidyverse learn basics of ggplot2 with a dataset describing global ocean health practice writing a script in RMarkdown practice the rstudio-github workflow 5.4 Install tidyverse: tidyverse We will use the ggplot2 package, which is bundled with a composite-package called tidyverse. Check out tidyverse.org/ for more information. We will download and install tidyverse: ## from CRAN: install.packages(&quot;tidyverse&quot;) ## do this once only to install the package on your computer. You will see some messages describing which packages were installed with tidyverse. Messages about name conflicts are also returned. This is not a problem its just an alert that two functions from dplyr will replace functions in the built-in stats package with the same name. 5.5 Create an RMarkdown file to work from To do: Create a new R Markdown file We will create the RMarkdown file you will be working from. You can write notes to yourself in Markdown and have a record of all your R code. Go to File &gt; New File &gt; R Markdown … (or click the green plus in the top left corner). Next, replace all the automatic text with the following: --- title: &quot;Graphics with ggplot2&quot; author: &quot;Julie&quot; date: &quot;11/21/2017&quot; output: html_document --- # Learning ggplot2 We&#39;re learning ggplot2 It&#39;s going to be amazing. Now, let’s save the file. I’m going to call my file ggplot2.Rmd. Do a pull…then stage/commit (to save to git history)…then push to sync with GitHub.com. 5.6 Load the tidverse We have downloaded the tidyverse package but it is not yet loaded in the R workspace. We will use the library() function to load tidyverse. This will be the first code chunk in your RMarkdown: library(tidyverse) ## do this every time you restart R and need it 5.7 Load and explore data We will load the dataset we will be using for this tutorial into our workspace directly from GitHub.com (I always find this GitHub functionality so cool!). ohi_data &lt;- read_csv(&quot;https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/OHI_global_data.csv&quot;) These data are from the global Ocean Health Index which assesses the condition of marine resources for 220 countries or territories. The dataset includes: variable description data type examples country OHI region name for country or territorial regions with marine coastline character Jarvis Island, Italy OHI_score Ocean Health Index scores describing condition of marine resources based on the 2017 global assessment numeric values can range from 0-100, with 100 being the best possible score OHI_trend average annual change in OHI scores from 2012 to 2017 numeric values range from -3.9 to 1.86, with positive values indicating improving scores coastal_pop human population within 25 miles of coast numeric values range from 0 to &gt;317 million log_coastal_pop log(coastal_pop + 1) numeric values range from 0 to ~20 cumulative_human_impact average cumulative impact of human stressors (e.g., SST, shipping, pollution) on marine ecosystems within the country’s marine boundaries numeric values range from 1.419 to 6.762, with larger values indicating higher impact HDI Human Development Index scores, which measure average achievement in key dimensions of human development: a long and healthy life, being knowledgeable and have a decent standard of living. numeric values are rescaled to be between 0 to 1, with higher scores indicating better human development georegion_one lower resolution UN georegion designations based on georegional and social similarities character Africa, Americas, Asia georegion_two higher resolution UN georegion designations based on georegional and social similarities character Australia and New Zealand, Eastern Asia, Caribbean Let’s explore these data, shall we: head(ohi_data) ## # A tibble: 6 x 9 ## country OHI_score OHI_trend coastal_pop log_coastal_pop cumulative_huma… ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 South … 92.0 1.67 0 0 2.82 ## 2 Crozet… 88.1 0.81 0 0 1.92 ## 3 Howlan… 87.7 0.08 0 0 2.97 ## 4 Heard … 87.4 0.46 0 0 2.78 ## 5 Kergue… 87.3 0.72 0 0 2.02 ## 6 Jarvis… 83.9 -0.25 0 0 1.85 ## # … with 3 more variables: HDI &lt;dbl&gt;, georegion_one &lt;chr&gt;, ## # georegion_two &lt;chr&gt; summary(ohi_data) ## country OHI_score OHI_trend coastal_pop ## Length:221 Min. :41.83 Min. :-3.9900 Min. : 0 ## Class :character 1st Qu.:61.62 1st Qu.:-0.5600 1st Qu.: 106224 ## Mode :character Median :67.82 Median :-0.1800 Median : 1066507 ## Mean :66.87 Mean :-0.2261 Mean : 11471246 ## 3rd Qu.:72.21 3rd Qu.: 0.1900 3rd Qu.: 7081969 ## Max. :91.98 Max. : 1.8600 Max. :317149893 ## ## log_coastal_pop cumulative_human_impact HDI ## Min. : 0.00 Min. :1.419 Min. :0.4140 ## 1st Qu.:11.57 1st Qu.:3.553 1st Qu.:0.5970 ## Median :13.88 Median :3.896 Median :0.7400 ## Mean :12.64 Mean :3.861 Mean :0.7159 ## 3rd Qu.:15.77 3rd Qu.:4.351 3rd Qu.:0.8270 ## Max. :19.57 Max. :6.762 Max. :0.9490 ## NA&#39;s :76 ## georegion_one georegion_two ## Length:221 Length:221 ## Class :character Class :character ## Mode :character Mode :character ## ## ## ## table(ohi_data$georegion_one) ## ## Africa Americas ## 46 3 ## Asia Europe ## 40 43 ## Latin America and the Caribbean Oceania ## 48 34 ## Southern Islands ## 7 table(ohi_data$georegion_two) ## ## Australia and New Zealand Caribbean ## 6 28 ## Central America Eastern Africa ## 9 17 ## Eastern Asia Eastern Europe ## 6 5 ## Melanesia Micronesia ## 5 13 ## Middle Africa Northern Africa ## 7 7 ## Northern America Northern Europe ## 3 19 ## Polynesia South America ## 10 11 ## South-Eastern Asia Southern Africa ## 12 2 ## Southern Asia Southern Europe ## 7 14 ## Southern Islands Western Africa ## 7 13 ## Western Asia Western Europe ## 15 5 5.8 Plotting with ggplot2 Plots are created using a step-wise approach that is flexible and easily customized. We will walk through the steps needed to build a plot in ggplot2. HINT: Start with the simplest version of your plot and build onto it. 5.8.1 Step 1: Identify the dataframe ggplot2 requires the data to be in a dataframe format. The first step is to use the ggplot() function to identify the dataframe with the data you want to plot. At this point, we will also assign the x and y axis variables within the aes function (this stands for aesthetics, and we will discuss this concept after we have a plot to work with). [NOTE: This step was confusing for me for a long time because it doesn’t actually make the plot!] ggplot(data = ohi_data, aes(x = OHI_score, y = HDI)) 5.8.2 Step 2: Identify the style of plot you want to create (i.e., the geom) Next, we will actually create the plot by adding a geom function using the + operator. A geom is the geometrical object that a plot uses to represent data. For example, bar charts use bar geoms, line charts use line geoms, boxplots use boxplot geoms, and so on. You can use different geoms to plot the same data. To change the type of plot, change the geom function that you add to ggplot(). ggplot2 provides over 30 geoms, which are described in the official ggplot2 cheatsheet. To learn more about any single geom, use help: ?geom_smooth. Extension packages provide even more geoms (see https://www.ggplot2-exts.org for a sampling). We will start by creating a scatterplot of ohi scores within UN georegions by adding the geom_point function. ggplot(data = ohi_data, aes(x = georegion_one, y =OHI_score)) + geom_point() Yay! A plot! Next we will replace geom_point() with geom_jitter() to create a style of plot with the same data. geom_jitter is similar to geom_point, but it adds random variation to values along the x-axis to separate points: ggplot(data = ohi_data, aes(x = georegion_one, y =OHI_score)) + geom_jitter(width=0.2) # the width argument describes how much scatter to add Now we will explore other geoms. The following bar plot uses geom_bar to describe the number of countries in each UN category: ggplot(data = ohi_data, aes(x = georegion_one)) + geom_bar() A histogram using geom_histogram: ggplot(data = ohi_data, aes(x = HDI)) + geom_histogram() Multiple geoms can be layered on the same plot. Geom layers can be added using either the same or different dataframes. To demonstrate this we will use a secondary dataset with the mean OHI score for each UN georegion. We will create a bar plot of the means for each region and then overlay the point data. ohi_summary &lt;- read_csv(&quot;https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/OHI_scores_georegion_summary.csv&quot;) ohi_summary ## # A tibble: 7 x 2 ## georegions OHI_score_average ## &lt;chr&gt; &lt;dbl&gt; ## 1 Africa 59.7 ## 2 Americas 68.3 ## 3 Asia 63.9 ## 4 Europe 68.5 ## 5 Latin America and the Caribbean 67.0 ## 6 Oceania 75.0 ## 7 Southern Islands 80.1 ggplot(data = ohi_summary, aes(x = georegions, y = OHI_score_average)) + geom_bar(stat=&quot;identity&quot;) + geom_jitter(data=ohi_data, aes(x=georegion_one, y=OHI_score)) In the above example, the global mappings are designated by: ggplot(data = ohi_summary, aes(x = georegions, y = OHI_score_average)). These are then overwritten by the local mappings designated in the geom_jitter layer. The global designations will apply to subsequent layers, unless otherwise changed. This makes it possible to display different aesthetics and data in different layers. STOP: let’s Commit, Pull and Push to GitHub And discuss the following In the code below, why isn’t the data showing up? ggplot(data = ohi_data, aes(y = OHI_score, x = HDI, color=georegion_one)) Are these two approaches the same? ggplot(data = ohi_data, aes(y=OHI_score, x = HDI, color=georegion_one)) + geom_point() ggplot(data = ohi_data) + geom_point(aes(y = OHI_score, x = HDI, color=georegion_one)) Answers The code is missing a geom to describe how the data should be plotted. These two approaches result in the same plot here, but there could be downstream effects as more layers are added. More about the aes function The arguments within aes() link variables in the dataframe to some aspect of plot appearance. As we have discussed, x and y describe the axes, but other arguments can be added to describe a z variable (e.g. size or color or shape of points). Here are some examples of aes arguments: color color of lines/points fill color within polygons label name linetype type of line shape style of point alpha transparency (0-1) size size of shape This is very powerful! Let’s explore. Changing the point size: ggplot(data = ohi_data, aes(x = OHI_score, y = HDI, size = coastal_pop)) + geom_point() Changing the color: continuous variable ggplot(data = ohi_data, aes(x = OHI_score, y = HDI, color = coastal_pop)) + geom_point() Changing the color: discrete variable ggplot(data = ohi_data, aes(x = OHI_score, y = HDI, color = georegion_one)) + geom_point() Changing shape of points ggplot(data = ohi_data, aes(x = OHI_score, y = HDI, shape = georegion_one)) + geom_point() Adding labels #This doesn&#39;t add the labels like it seems like it should: ggplot(data = ohi_data, aes(x = OHI_score, y = HDI, label=country)) + geom_point(aes(x = OHI_score, y = HDI)) # To do this we have to add a geom_text function ggplot(data = ohi_data, aes(x = OHI_score, y = HDI, label=country)) + geom_point(aes(x = OHI_score, y = HDI)) + geom_text() 5.8.3 Step 3: Customize your plot So far, the plots we have created are fairly ugly and hard to read. We will now improve these basic plots using a stepwise approach. 5.8.3.1 Themes I do not like the default ggplot2 figures because I find them too busy. A quick way to improve plot appearance is to use themes. Many themes are built into the ggplot2 package. For example, theme_bw() removes the gray background. Once you start typing theme_ a list of options will pop up. ggplot(data = ohi_data, aes(x = OHI_score, y = HDI)) + geom_point() + theme_bw() The ggthemes package provides many additional themes (including a Tufte theme..which is very clean and data oriented). The ggplot2 extensions website provides a list of packages that extend the capabilities of ggplot2, including additional themes. I often create my own themes to make figures that work well in publications or presentations. This also gives my figures a consistent look (without having to remember from figure to figure the size of labels, etc.). I have found that storing my themes on Github works well. Here is an example of a theme I created named “scatterTheme”: source(&#39;https://raw.githubusercontent.com/OHI-Science/ohiprep/master/src/R/scatterTheme.txt&#39;) ggplot(data = ohi_data, aes(x = OHI_score, y = HDI)) + geom_point() + scatterTheme 5.8.3.2 Labels: axis, plot, legend One of the first things you will often want to do is alter labels for: titles, axes, figure legends, etc. These modifications involve manipulating the theme function and can quickly get complicated, and I typically have to Google the specifics or refer to a cheatsheet, despite using ggplot2 for years and years and years. But, some key changes are easy to make using the labs function: ggplot(data = ohi_data, aes(y = OHI_score, x = HDI, color=georegion_one)) + geom_point() + labs(y = &quot;OHI score, 2017&quot;, x = &quot;Human Development Index&quot;, title = &quot;Countries with high human development have more sustainable oceans&quot;, color = &quot;Georegion&quot;) + # if color doesn&#39;t work, use &quot;fill&quot; theme_bw() We interrupt this section on customizing your plot for an exercise (5 min) Make a histogram of the OHI_score variable and color by the georegion_one variable. How would you make all the bars on your histogram light gray? Hint: use argument fill = &quot;lightgray&quot;. Where is the best place to add this in your code to get this to work? Play with some themes and customizing title and axes labels. Try changing the text sizes and angles (refer to the cheatsheet). Answers (no peeking) # 1. This one is tricky because the color aesthetic only does the outline of the bars. # If you got that far, you were halfway there. # You will need to use the fill argument to color shapes my_plot &lt;- ggplot(data = ohi_data, aes(x=OHI_score, fill=georegion_one)) + geom_histogram() my_plot # 2. This was something that confused me for a while. My instinct was to add it to the aes function....BUT NO!!! # The arguments in aes should correspond to a column in the dataframe. The best place for this argument is in # the geom function (and not in an aes function) ggplot(data = ohi_data, aes(x=OHI_score)) + geom_histogram(fill=&quot;lightgray&quot;) # 3. my_plot + # the plot created in question 1 continued... labs(x = &quot;OHI score&quot;, y = &quot;Number of countries&quot;, title = &quot;Distribution of OHI scores&quot;) + theme_light() + theme(legend.title = element_blank(), axis.text.x = element_text(angle = 45, hjust = 1, size = 14), axis.text.y = element_text(size = 14), axis.title = element_text(size = 16) ) STOP: commit, pull and push to github We will now continue with customizing your plot….. 5.8.3.3 Global changes to plot attributes It is easy to make global changes to your plot’s appearance (these go outside the aes function). Here are some options: color color of lines/points fill color within polygons label if points are a character linetype type of line shape style of point alpha transparency (0-1) size size of shape Here are the R shapes with their reference numbers: Here are the R line types with their reference numbers: With this information, we can improve the appearance of one of our previous figures: ggplot(data = ohi_summary, aes(x = georegions, y = OHI_score_average)) + geom_bar(stat=&quot;identity&quot;, fill = &quot;lightgray&quot;) + geom_jitter(data=ohi_data, aes(x=georegion_one, y=OHI_score), color=&quot;red&quot;, size=3, alpha=0.3) + theme_bw() 5.8.3.4 Color One of the more challenging aspects of creating a good plot is selecting colors. We are here to help! Hint 1 Unless you are doing something very simple (e.g. 1-3 colors), I recommend using established color palettes. There are many color palette packages (here is a good resource: https://github.com/EmilHvitfeldt/r-color-palettes), but one of the best known is RColorBrewer. Here we will explore using the RColorBrewer palettes. Install the RColorBrewer and colorspace packages (only needs to be done once). Both RColorBrewer and colorspace have nice palettes and colorspace has additional functions for dealing with color. install.packages(&quot;RColorBrewer&quot;) install.packages(&quot;colorspace&quot;) Load packages into working space: library(&quot;RColorBrewer&quot;) library(&quot;colorspace&quot;) To see the available palettes in RColorBrewer: display.brewer.all() To select a palette: my_palette &lt;- brewer.pal(n=9, &quot;YlOrRd&quot;) Hint 2 R uses hexidecimal to represent colors. Hexadecimal is a base-16 number system used to describe color. Red, green, and blue are each represented by two characters (#rrggbb). Each character has 16 possible symbols: 0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F “00” can be interpreted as 0.0 and “FF” as 1.0, i.e., red= #FF0000 , black=#000000, white = #FFFFFF Two additional characters (with the same scale) can be added to the end to describe transparency (#rrggbbaa) A color palette is actually just a simple vector of hexidecimal values: my_palette ## [1] &quot;#FFFFCC&quot; &quot;#FFEDA0&quot; &quot;#FED976&quot; &quot;#FEB24C&quot; &quot;#FD8D3C&quot; &quot;#FC4E2A&quot; &quot;#E31A1C&quot; ## [8] &quot;#BD0026&quot; &quot;#800026&quot; I always use hexidecimal format for colors in R because it is the most direct approach. Hint 3 The function you will want to use to specify color in ggplot2 depends on whether the color is mapped to a discrete/categorical data variable, or a continuous variable. There are a LOT of options in ggplot2, but these are the approaches I have settled on because they are the most flexible: In the following case we map color to a continuous variable, so we will use the scale_color_gradientn function with the palette we selected above: ggplot(data = ohi_data, aes(x = OHI_score, y = OHI_trend, color = HDI)) + geom_point(size =3) + scale_colour_gradientn(colors = my_palette) This function takes a vector of colors and interpolates between the colors to get a gradient. If we are mapping color to a discrete variable, we will use the scale_color_manual function: # lets use a discrete color scale my_palette &lt;- brewer.pal(n=12, &quot;Set3&quot;) ggplot(data = ohi_data, aes(x = OHI_score, y = HDI, color = georegion_one)) + geom_point(size = 3) + scale_color_manual(values = my_palette) # Note the first 7 of the 12 colors are used in the plot The scale_color_manual function also has a lot of great arguments that allow you to control which colors are associated with each factor level, the names used in the legend, and other controls. Hint 4 If the “color” functions aren’t working, try the “fill” version of the function. Challenge With all of this information in hand, please take a few minutes to create a plot using the fake dataset we will create below (or one of the other datasets we have worked with). # making a fake dataframe fake_data &lt;- data.frame(animal = rep(c(&quot;cat&quot;, &quot;dog&quot;, &quot;hamster&quot;), each=10), year = 2011:2020, values = c(rnorm(n=10, 5, 1) * seq(0.1, 0.5, length.out=10), rnorm(n=10, 8, 1) * seq(0.1, 0.5, length.out=10), rnorm(n=10, 10, 1) * seq(0.1, 0.5, length.out=10))) ## Add your code to create a plot: Answers (no peeking!) Here is one approach, but there is a lot more to do to make this really nice! library(ggthemes) ggplot(data = fake_data, aes(x = as.factor(year), y = values, group=animal, color=animal)) + geom_point(size = 3) + geom_line(size=2, alpha = 0.5) + labs(x = &quot;year&quot;, color = &quot;&quot;) + theme_tufte() 5.9 Saving plots After creating your plot, use the ggsave() function to save your plot. This function allows you easily change the dimension, resolution, and format of your plot: my_plot &lt;- ggplot(data = fake_data, aes(x = as.factor(year), y = values, group=animal, color=animal)) + geom_point(size = 3) + geom_line(size=2, alpha = 0.5) + labs(x = &quot;year&quot;, color = &quot;&quot;) + theme_tufte() ggsave(&quot;name_of_file.png&quot;, my_plot, width = 15, height = 10, dpi=300) Note: The parameters width and height also determine the font size in the saved plot. 5.10 Arranging plots I am a huge fan of cowplots for making multiplot figures. Here is a nice introduction. install.packages(&quot;cowplot&quot;) library(cowplot) ## Error in library(cowplot): there is no package called &#39;cowplot&#39; score_vs_trend &lt;- ggplot(data=ohi_data, aes(x=OHI_score, y=OHI_trend)) + geom_point(size=3, alpha=0.4) score_vs_trend # notice that the default theme has been changed....I really like this theme! score_vs_HDI &lt;- ggplot(data=ohi_data, aes(x=OHI_score, y=HDI)) + geom_point(size=3, alpha=0.4) + geom_smooth() plot_grid(score_vs_trend, score_vs_HDI, labels = c(&#39;A&#39;, &#39;B&#39;)) ## Error in plot_grid(score_vs_trend, score_vs_HDI, labels = c(&quot;A&quot;, &quot;B&quot;)): could not find function &quot;plot_grid&quot; 5.11 Interactive plots So as you can see, ggplot2 is a fantastic package for visualizing data. But there are some additional packages that let you make plots interactive. plotly, gganimate. I use plotly all the time to check my data! install.packages(&quot;plotly&quot;) library(plotly) ## Error in library(plotly): there is no package called &#39;plotly&#39; score_vs_HDI &lt;- ggplot(data=ohi_data, aes(x=OHI_score, y=HDI, text=paste0(&quot;Country: &quot;, country))) + geom_point(size=3, alpha=0.4) ggplotly(score_vs_HDI) ## Error in ggplotly(score_vs_HDI): could not find function &quot;ggplotly&quot; 5.12 Save and push to GitHub "],
["dplyr.html", "Chapter 6 Data Wrangling: dplyr 6.1 Objectives &amp; Resources 6.2 Tidy Data 6.3 Explore the gapminder data.frame 6.4 dplyr basics 6.5 filter() subsets data row-wise (observations). 6.6 Your turn 6.7 select() subsets data column-wise (variables) 6.8 Use select() and filter() together 6.9 Meet the new pipe %&gt;% operator 6.10 mutate() adds new variables 6.11 group_by() operates on groups 6.12 arrange() orders columns 6.13 All together now 6.14 Joining datasets 6.15 Key Points 6.16 Troubleshooting.", " Chapter 6 Data Wrangling: dplyr Data scientists, according to interviews and expert estimates, spend from 50 percent to 80 percent of their time mired in the mundane labor of collecting and preparing data, before it can be explored for useful information. - NYTimes (2014) 6.1 Objectives &amp; Resources What are some common things you like to do with your data? Maybe remove rows or columns, do calculations and maybe add new columns? This is called data wrangling. It’s not data management or data manipulation: you keep the raw data raw and do these things programatically in R with the tidyverse. We are going to introduce you to data wrangling in R first with the tidyverse. The tidyverse is a suite of packages that match a philosophy of data science developed by Hadley Wickham and the RStudio team. I find it to be a more straight-forward way to learn R. We will also show you by comparison what code will look like in “Base R”, which means, in R without any additional packages (like the “tidyverse” package) installed. I like David Robinson’s blog post on the topic of teaching the tidyverse first. For some things, base-R is more straight forward, and we’ll show you that too. Whenever we use a function that is from the tidyverse, we will prefix it so you’ll know for sure. 6.1.1 Objectives discuss tidy data read data from online into R explore gapminder data with base-R functions wrangle gapminder data with dplyr tidyverse functions practice RStudio-GitHub workflow 6.1.2 Resources Today’s materials are again borrowing from some excellent sources, including: Jenny Bryan’s lectures from STAT545 at UBC: Introduction to dplyr Hadley Wickham and Garrett Grolemund’s R for Data Science Software Carpentry’s R for reproducible scientific analysis materials: Dataframe manipulation with dplyr First developed for Software Carpentry at UCSB RStudio’s data wrangling cheatsheet RStudio’s data wrangling webinar 6.1.3 Data and packages Gapminder data We’ll be using Gapminder data, which represents the health and wealth of nations. It was pioneered by Hans Rosling, who is famous for describing the prosperity of nations over time through famines, wars and other historic events with this beautiful data visualization in his 2006 TED Talk: The best stats you’ve ever seen: Gapminder Motion Chart We’ll use the package dplyr, which is bundled within the tidyverse package. Please install the tidyverse ahead of time: install.packages(&quot;tidyverse&quot;) 6.2 Tidy Data Let’s start off discussing Tidy Data. Hadley Wickham, RStudio’s Chief Scientist, and his team have been building R packages for data wrangling and visualization based on the idea of tidy data. Tidy data has a simple convention: put variables in the columns and observations in the rows. The Ocean Health Index dataset we were working with this morning was an example of tidy data. When data are tidy, you are set up to work with it for your analyses, plots, etc. Right now we are going to use dplyr to wrangle this tidy-ish data set (the transform part of the cycle), and then come back to tidying messy data using tidyr once we’ve had some fun wrangling. These are both part of the tidyverse package that we’ve already installed: Conceptually, making data tidy first is really critical. Instead of building your analyses around whatever (likely weird) format your data are in, take deliberate steps to make your data tidy. When your data are tidy, you can use a growing assortment of powerful analytical and visualization tools instead of inventing home-grown ways to accommodate your data. This will save you time since you aren’t reinventing the wheel, and will make your work more clear and understandable to your collaborators (most importantly, Future You). And actually, Hadley Wickham and RStudio have created a ton of packages that help you at every step of the way here. This is from one of Hadley’s recent presentations: 6.2.1 Setup We’ll do this in a new RMarkdown file. Here’s what to do: Clear your workspace (Session &gt; Restart R) New File &gt; R Markdown… Save as gapminder-wrangle.Rmd Delete the irrelevant text and write a little note to yourself about how we’ll be wrangling gapminder data using dplyr. You can edit the title too if you need to. 6.2.2 load tidyverse (which has dplyr inside) In your R Markdown file, let’s make sure we’ve got our libraries loaded. Write the following: library(tidyverse) ## install.packages(&quot;tidyverse&quot;) This is becoming standard practice for how to load a library in a file, and if you get an error that the library doesn’t exist, you can install the package easily by running the code within the comment (highlight install.packages(&quot;tidyverse&quot;) and run it). 6.3 Explore the gapminder data.frame In the ggplot2 chapter, we explored the Ocean Health Index data visually. Today, we’ll explore a different dataset by the numbers. We will work with some of the data from the Gapminder project. The data are on GitHub. Navigate there by going to: github.com &gt; ohi-science &gt; data-science-training &gt; data &gt; gapminder.csv or by copy-pasting url for data-view: https://github.com/OHI-Science/data-science-training/blob/master/data/gapminder.csv This is data-view mode: so we can have a quick look at the data. It’s a .csv file, which you’ve probably encountered before, but GitHub has formatted it nicely so it’s easy to look at. You can see that for every country and year, there are several columns with data in them. 6.3.1 read data with readr::read_csv() We can read this data into R directly from GitHub, without downloading it. But we can’t read this data in view-mode. We have to click on the Raw button on the top-right of the data. This displays it as the raw csv file, without formatting. Copy the url for raw data: https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/gapminder.csv Now, let’s go back to RStudio. In our R Markdown, let’s read this csv file and name the variable “gapminder”. We will use the read_csv() function from the readr package (part of the tidyverse, so it’s already installed!). ## read gapminder csv. Note the readr:: prefix identifies which package it&#39;s in gapminder &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/gapminder.csv&#39;) Note: read_csv works with local filepaths as well, you could use one from your computer. Let’s inspect: ## explore the gapminder dataset gapminder # this is super long! Let&#39;s inspect in different ways Let’s use head and tail: head(gapminder) # shows first 6 tail(gapminder) # shows last 6 head(gapminder, 10) # shows first X that you indicate tail(gapminder, 12) # guess what this does! str() will provide a sensible description of almost anything: when in doubt, inspect using str() on some of the recently created objects to get some ideas about what to do next. str(gapminder) # ?str - displays the structure of an object gapminder is a data.frame. We aren’t going to get into the other types of data receptacles today (‘arrays’, ‘matrices’), because working with data.frames is what you should primarily use. Why? data.frames package related variables neatly together, great for analysis most functions, including the latest and greatest packages actually require that your data be in a data.frame data.frames can hold variables of different flavors such as character data (country or continent names; “Characters (chr)”) quantitative data (years, population; “Integers (int)” or “Numeric (num)”) categorical information (male vs. female) We can also see the gapminder variable in RStudio’s Environment pane (top right) More ways to learn basic info on a data.frame. names(gapminder) dim(gapminder) # ?dim dimension ncol(gapminder) # ?ncol number of columns nrow(gapminder) # ?nrow number of rows A statistical overview can be obtained with summary(), or with skimr::skim() summary(gapminder) library(skimr) # install.packages(&#39;skimr&#39;) skim(gapminder) 6.3.2 Look at the variables inside a data.frame To specify a single variable from a data.frame, use the dollar sign $. The $ operator is a way to extract of replace parts of an object — check out the help menu for $. It’s a common operator you’ll see in R. gapminder$lifeExp # very long! hard to make sense of... head(gapminder$lifeExp) # can do the same tests we tried before str(gapminder$lifeExp) # it is a single numeric vector summary(gapminder$lifeExp) # same information, formatted slightly differently 6.4 dplyr basics OK, so let’s start wrangling with dplyr. There are five dplyr functions that you will use to do the vast majority of data manipulations: filter(): pick observations by their values select(): pick variables by their names mutate(): create new variables with functions of existing variables summarise(): collapse many values down to a single summary arrange(): reorder the rows These can all be used in conjunction with group_by() which changes the scope of each function from operating on the entire dataset to operating on it group-by-group. These six functions provide the verbs for a language of data manipulation. All verbs work similarly: The first argument is a data frame. The subsequent arguments describe what to do with the data frame. You can refer to columns in the data frame directly without using $. The result is a new data frame. Together these properties make it easy to chain together multiple simple steps to achieve a complex result. 6.5 filter() subsets data row-wise (observations). You will want to isolate bits of your data; maybe you want to only look at a single country or a few years. R calls this subsetting. filter() is a function in dplyr that takes logical expressions and returns the rows for which all are TRUE. Visually, we are doing this (thanks RStudio for your cheatsheet): Remember your logical expressions? We’ll use &lt; and == here. filter(gapminder, lifeExp &lt; 29) You can say this out loud: “Filter the gapminder data for life expectancy less than 29”. Notice that when we do this, all the columns are returned, but only the rows that have the life expectancy less than 29. We’ve subsetted by row. Let’s try another: “Filter the gapminder data for the country Mexico”. filter(gapminder, country == &quot;Mexico&quot;) How about if we want two country names? We can’t use the == operator here, because it can only operate on one thing at a time. We will use the %in% operator: filter(gapminder, country %in% c(&quot;Mexico&quot;, &quot;Peru&quot;)) How about if we want Mexico in 2002? You can pass filter different criteria: filter(gapminder, country == &quot;Mexico&quot;, year == 2002) 6.6 Your turn What was the average life expectency in Brazil between 1987 and 2007? Hint: do this in 2 steps by assigning a variable and then using the mean() function. Then, sync to Github.com (pull, stage, commit, push). 6.6.1 Answer This is one way to do it based on what we have learned so far: x &lt;- filter(gapminder, country == &quot;Brazil&quot;, year &gt; 1986) mean(x$lifeExp) 6.7 select() subsets data column-wise (variables) We use select() to subset the data on variables or columns. Visually, we are doing this (thanks RStudio for your cheatsheet): We can select multiple columns with a comma, after we specify the data frame (gapminder). select(gapminder, year, country, lifeExp) We can also use - to deselect columns select(gapminder, -continent, -lifeExp) # you can use - to deselect columns 6.8 Use select() and filter() together Let’s filter for Cambodia and remove the continent and lifeExp columns. We’ll save this as a variable. Actually, as two temporary variables, which means that for the second one we need to operate on gap_cambodia, not gapminder. gap_cambodia &lt;- filter(gapminder, country == &quot;Cambodia&quot;) gap_cambodia2 &lt;- select(gap_cambodia, -continent, -lifeExp) We also could have called them both gap_cambodia and overwritten the first assignment. Either way, naming them and keeping track of them gets super cumbersome, which means more time to understand what’s going on and opportunities for confusion or error. Good thing there is an awesome alternative. 6.9 Meet the new pipe %&gt;% operator Before we go any further, we should explore the new pipe operator that dplyr imports from the magrittr package by Stefan Bache. This is going to change your life. You no longer need to enact multi-operation commands by nesting them inside each other. And we won’t need to make temporary variables like we did in the Cambodia example above. This new syntax leads to code that is much easier to write and to read: it actually tells the story of your analysis. Here’s what it looks like: %&gt;%. The RStudio keyboard shortcut: Ctrl + Shift + M (Windows), Cmd + Shift + M (Mac). Let’s demo then I’ll explain: gapminder %&gt;% head() This is equivalent to head(gapminder). This pipe operator takes the thing on the left-hand-side and pipes it into the function call on the right-hand-side. It literally drops it in as the first argument. Never fear, you can still specify other arguments to this function! To see the first 3 rows of Gapminder, we could say head(gapminder, 3) or this: gapminder %&gt;% head(3) I’ve advised you to think “gets” whenever you see the assignment operator, &lt;-. Similarly, you should think “and then” whenever you see the pipe operator, %&gt;%. One of the most awesome things about this is that you START with the data before you say what you’re doing to DO to it. So above: “take the gapminder data, and then give me the first three entries”. This means that instead of this: ## instead of this... gap_cambodia &lt;- filter(gapminder, country == &quot;Cambodia&quot;) gap_cambodia2 &lt;- select(gap_cambodia, -continent, -lifeExp) ## ...we can do this gap_cambodia &lt;- gapminder %&gt;% filter(country == &quot;Cambodia&quot;) gap_cambodia2 &lt;- gap_cambodia %&gt;% select(-continent, -lifeExp) So you can see that we’ll start with gapminder in the first example line, and then gap_cambodia in the second. This makes it a bit easier to see what data we are starting with and what we are doing to it. …But, we still have those temporary variables so we’re not truly that better off. But get ready to be majorly impressed: 6.9.1 Revel in the convenience We can use the pipe to chain those two operations together: gap_cambodia &lt;- gapminder %&gt;% filter(country == &quot;Cambodia&quot;) %&gt;% select(-continent, -lifeExp) What’s happening here? In the second line, we were able to delete gap_cambodia2 &lt;- gap_cambodia, and put the pipe operator above. This is possible since we wanted to operate on the gap_cambodia data anyways. And we weren’t truly excited about having a second variable named gap_cambodia2 anyways, so we can get rid of it. This is huge, because most of your data wrangling will have many more than 2 steps, and we don’t want a gap_cambodia14! By using multiple lines I can actually read this like a story and there aren’t temporary variables that get super confusing. In my head: “start with the gapminder data, and then filter for Cambodia, and then drop the variables continent and lifeExp.” Being able to read a story out of code like this is really game-changing. We’ll continue using this syntax as we learn the other dplyr verbs. 6.10 mutate() adds new variables Alright, let’s keep going. Let’s say we needed to add an index column so we know which order these data came in. Let’s not make a new variable, let’s add a column to our gapminder data frame. How do we do that? With the mutate() function. Visually, we are doing this (thanks RStudio for your cheatsheet): Imagine we want to know each country’s annual GDP. We can multiply pop by gdpPercap to create a new column named gdp. gapminder %&gt;% mutate(gdp = pop * gdpPercap) 6.10.1 Your turn Calculate the population in thousands for all Asian countries in the year 2007 and add it as a new column. Then, sync to Github.com (pull, stage, commit, push). 6.10.1.1 Answer gapminder %&gt;% filter(continent == &quot;Asia&quot;, year == 2007) %&gt;% mutate(pop_thousands = pop/1000) %&gt;% select(country, year, pop_thousands) #this cleans up the dataframe but isn&#39;t necessary 6.11 group_by() operates on groups What if we wanted to know the total population on each continent in 2002? Answering this question requires a grouping variable. Visually, we are doing this (thanks RStudio for your cheatsheet): By using group_by() we can set our grouping variable to continent and create a new column called cont_pop that will add up all country populations by their associated continents. gapminder %&gt;% filter(year == 2002) %&gt;% group_by(continent) %&gt;% mutate(cont_pop = sum(pop)) OK, this is great. But what if we don’t care about the other columns and we only want each continent and their population in 2002? Here’s the next function: 6.11.1 summarize() with group_by() We want to operate on a group, but actually collapse or distill the output from that group. The summarize() function will do that for us. Visually, we are doing this (thanks RStudio for your cheatsheet): Here we go: gapminder %&gt;% group_by(continent) %&gt;% summarize(cont_pop = sum(pop)) %&gt;% ungroup() How cool is that! summarize() will actually only keep the columns that are grouped_by or summarized. So if we wanted to keep other columns, we’d have to do have a few more steps (we’ll get into it tomorrow). ungroup() removes the grouping and it’s good to get in the habit of using it after a group_by(). We can use more than one grouping variable. Let’s get total populations by continent and year. gapminder %&gt;% group_by(continent, year) %&gt;% summarize(cont_pop = sum(pop)) 6.12 arrange() orders columns This is ordered alphabetically, which is cool. But let’s say we wanted to order it in ascending order for year. The dplyr function is arrange(). gapminder %&gt;% group_by(continent, year) %&gt;% summarize(cont_pop = sum(pop)) %&gt;% arrange(year) 6.12.1 Your turn What is the maximum GDP per continent across all years? 6.12.1.1 Answer gapminder %&gt;% mutate(gdp = pop * gdpPercap) %&gt;% group_by(continent) %&gt;% mutate(max_gdp = max(gdp)) %&gt;% filter(gdp == max_gdp) ## Error in eval(lhs, parent, parent): object &#39;gapminder&#39; not found 6.12.2 Your turn arrange your data frame in descending order (opposite of what we’ve done). Expect that this is possible: ?arrange save your data frame as a variable find the maximum life expectancy for countries in Asia. What is the earliest year you encounter? The latest? Hint: you can use or base::max and dplyr::arrange()… Knit your RMarkdown file, and sync it to GitHub (pull, stage, commit, push) 6.12.2.1 Answer (no peeking!) asia_life_exp &lt;- gapminder %&gt;% filter(continent == &#39;Asia&#39;) %&gt;% group_by(country) %&gt;% filter(lifeExp == max(lifeExp)) %&gt;% arrange(year) 6.13 All together now We have done a pretty incredible amount of work in a few lines. Our whole analysis is this. Imagine the possibilities from here. It’s very readable: you see the data as the first thing, it’s not nested. Then, you can read the verbs. This is the whole thing, with explicit package calls from readr:: and dplyr::: ## gapminder-wrangle.R ## J. Lowndes lowndes@nceas.ucsb.edu ## load libraries library(tidyverse) ## install.packages(&#39;tidyverse&#39;) ## read in data gapminder &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/gapminder.csv&#39;) ## summarize gap_max_life_exp &lt;- gapminder %&gt;% dplyr::select(-continent, -lifeExp) %&gt;% # or select(country, year, pop, gdpPercap) dplyr::group_by(country) %&gt;% dplyr::mutate(gdp = pop * gdpPercap) %&gt;% dplyr::summarize(max_gdp = max(gdp)) %&gt;% dplyr::ungroup() I actually am borrowing this “All together now” from Tony Fischetti’s blog post How dplyr replaced my most common R idioms). With that as inspiration, this is how what we have done would look like in Base R. 6.13.1 Compare to base R Let’s compare with some base R code to accomplish the same things. Base R requires subsetting with the [rows, columns] notation. This notation is something you’ll see a lot in base R. the brackets [ ] allow you to extract parts of an object. Within the brackets, the comma separates rows from columns. If we don’t write anything after the comma, that means “all columns”. And if we don’t write anything before the comma, that means “all rows”. Also, the $ operator is how you access specific columns of your dataframe. You can also add new columns like we will do with mex$gdp below. Instead of calculating the max for each country like we did with dplyr above, here we will calculate the max for one country, Mexico. Tomorrow we will learn how to do it for all the countries, like we did with dplyr::group_by(). ## gapminder-wrangle.R --- baseR ## J. Lowndes lowndes@nceas.ucsb.edu gapminder &lt;- read.csv(&#39;https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/gapminder.csv&#39;, stringsAsFactors = FALSE) x1 &lt;- gapminder[ , c(&#39;country&#39;, &#39;year&#39;, &#39;pop&#39;, &#39;gdpPercap&#39;) ]# subset columns mex &lt;- x1[x1$country == &quot;Mexico&quot;, ] # subset rows mex$gdp &lt;- mex$pop * mex$gdpPercap # add new columns mex$max_gdp &lt;- max(mex$gdp) Note too that the chain operator %&gt;% that we used with the tidyverse lets us get away from the temporary variable x1. 6.13.2 Your Turn Get your RMarkdown file cleaned up and sync it for the last time today! 6.13.2.1 Answers … 6.14 Joining datasets We’ve learned a ton in this session and we may not get to this right now. If we don’t have time, we’ll start here before getting into the next chapter: tidyr. Most of the time you will have data coming from different places or in different files, and you want to put them together so you can analyze them. Datasets you’ll be joining can be called relational data, because it has some kind of relationship between them that you’ll be acting upon. In the tidyverse, combining data that has a relationship is called “joining”. From the RStudio cheatsheet (note: this is an earlier version of the cheatsheet but I like the graphics): Let’s have a look at this and pretend that the x1 column is a study site and x2 is the variables we’ve recorded (like species count) and x3 is data from an instrument (like temperature data). Notice how you may not have exactly the same observations in the two datasets: in the x1 column, observations A and B appear in both datasets, but notice how the table on the left has observation C, and the table on the right has observation D. If you wanted to combine these two tables, how would you do it? There are some decisions you’d have to make about what was important to you. The cheatsheet visualizes it for us: We will only talk about this briefly here, but you can refer to this more as you have your own datasets that you want to join. This describes the figure above:: left_join keeps everything from the left table and matches as much as it can from the right table. In R, the first thing that you type will be the left table (because it’s on the left) right_join keeps everything from the right table and matches as much as it can from the left table inner_join only keeps the observations that are similar between the two tables full_join keeps all observations from both tables. Let’s play with these CO2 emissions data to illustrate: ## read in the data. (same URL as yesterday, with co2.csv instead of gapminder.csv) co2 &lt;- read_csv(&quot;https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/co2.csv&quot;) ## explore co2 %&gt;% head() co2 %&gt;% dim() # 12 ## create new variable that is only 2007 data gap_2007 &lt;- gapminder %&gt;% filter(year == 2007) gap_2007 %&gt;% dim() # 142 ## left_join gap_2007 to co2 lj &lt;- left_join(gap_2007, co2, by = &quot;country&quot;) ## explore lj %&gt;% dim() #142 lj %&gt;% summary() # lots of NAs in the co2_2017 columm lj %&gt;% View() ## right_join gap_2007 and co2 rj &lt;- right_join(gap_2007, co2, by = &quot;country&quot;) ## explore rj %&gt;% dim() # 12 rj %&gt;% summary() rj %&gt;% View() That’s all we’re going to talk about today with joining, but there are more ways to think about and join your data. Check out the Relational Data Chapter in R for Data Science. 6.15 Key Points Data manipulation functions in dplyr allow you to filter() by rows and select() by columns, create new columns with mutate(), and group_by() unique column values to apply summarize() for new columns that define aggregate values across groupings. The “then” operator %&gt;% allows you to chain successive operations without needing to define intermediary variables for creating the most parsimonious, easily read analysis. 6.16 Troubleshooting. 6.16.1 Error: unexpected SPECIAL in &quot; %&gt;%&quot; If you get this error, it is probably because you have a line that starts with a pipe. The pipe should be at the end of the previous line, not the start of the current line. Yes: gap_cambodia &lt;- gapminder %&gt;% filter(country == &quot;Cambodia&quot;) %&gt;% select(-continent, -lifeExp) No: gap_cambodia &lt;- gapminder %&gt;% filter(country == &quot;Cambodia&quot;) %&gt;% select(-continent, -lifeExp) # Error: unexpected SPECIAL in &quot; %&gt;%&quot; "],
["tidyr.html", "Chapter 7 Data Wrangling: tidyr 7.1 Objectives &amp; Resources 7.2 tidyr basics 7.3 Explore gapminder dataset. 7.4 gather() data from wide to long format 7.5 Plot long format data 7.6 spread() 7.7 clean up and save your .Rmd 7.8 Other links", " Chapter 7 Data Wrangling: tidyr 7.1 Objectives &amp; Resources Now you have some experience working with tidy data and seeing the logic of wrangling when data are structured in a tidy way. But ‘real’ data often don’t start off in a tidy way, and require some reshaping to become tidy. The tidyr package is for reshaping data. You won’t use tidyr functions as much as you use dplyr functions, but it is incredibly powerful when you need it. 7.1.1 Objectives learn tidyr with the gapminder package practice the RStudio-GitHub workflow your turn: use the data wrangling cheat sheet to explore window functions 7.1.2 Resources These materials borrow heavily from: R for Data Science: Relational Data R for Data Science: Tidy Data 7.1.3 Data and packages We’ll use the package tidyr and dplyr, which are bundled within the tidyverse package. We’ll also be using the Gapminder data we used when learning dplyr. We will also explore several datasets that come in Base R, in the datasets package. 7.2 tidyr basics Remember, from the dplyr section, that tidy data means all rows are an observation and all columns are variables. Why is this important? Well, if your data are formatted in a standard way, you will be able to use analysis tools that operate on that standard way. Your analyses will be streamlined and you won’t have to reinvent the wheel every time you see data in a different. Let’s take a look at some examples. Data are often entered in a wide format where each row is often a site/subject/patient and you have multiple observation variables containing the same type of data. An example of data in a wide format is the AirPassengers dataset which provides information on monthly airline passenger numbers from 1949-1960. You’ll notice that each row is a single year and the columns are each month Jan - Dec. AirPassengers ## Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec ## 1949 112 118 132 129 121 135 148 148 136 119 104 118 ## 1950 115 126 141 135 125 149 170 170 158 133 114 140 ## 1951 145 150 178 163 172 178 199 199 184 162 146 166 ## 1952 171 180 193 181 183 218 230 242 209 191 172 194 ## 1953 196 196 236 235 229 243 264 272 237 211 180 201 ## 1954 204 188 235 227 234 264 302 293 259 229 203 229 ## 1955 242 233 267 269 270 315 364 347 312 274 237 278 ## 1956 284 277 317 313 318 374 413 405 355 306 271 306 ## 1957 315 301 356 348 355 422 465 467 404 347 305 336 ## 1958 340 318 362 348 363 435 491 505 404 359 310 337 ## 1959 360 342 406 396 420 472 548 559 463 407 362 405 ## 1960 417 391 419 461 472 535 622 606 508 461 390 432 This format is intuitive for data entry, but less so for data analysis. If you wanted to calculate the monthly mean, where would you put it? As another row? Often, data must be reshaped for it to become tidy data. What does that mean? There are four main verbs we’ll use, which are essentially pairs of opposites: turn columns into rows (gather()), turn rows into columns (spread()), turn a character column into multiple columns (separate()), turn multiple character columns into a single column (unite()) 7.3 Explore gapminder dataset. Yesterday we started off with the gapminder data in a format that was already tidy. But what if it weren’t? Let’s look at a different version of those data. The data are on GitHub. Navigate there by going to: github.com &gt; ohi-science &gt; data-science-training &gt; data &gt; gapminder_wide.csv or by copy-pasting this in the browser: https://github.com/OHI-Science/data-science-training/blob/master/data/gapminder_wide.csv First have a look at the data. You can see there are a lot more columns than the version we looked at before. This format is pretty common, because it can be a lot more intuitive to enter data in this way. Sometimes, as with the gapminder dataset, we have multiple types of observed data. It is somewhere in between the purely ‘long’ and ‘wide’ data formats: 3 “ID variables” (continent, country, year) 3 “Observation variables” (pop,lifeExp,gdpPercap). It’s pretty common to have data in this format in most cases despite not having ALL observations in 1 column, since all 3 observation variables have different units. But we can play with switching it to long format and wide to show what that means (i.e. long would be 4 ID variables and 1 observation variable). But we want it to be in a tidy way so that we can work with it more easily. So here we go. You use spread() and gather() to transform or reshape data between wide to long formats. 7.3.1 Setup OK let’s get going. We’ll learn tidyr in an RMarkdown file within a GitHub repository so we can practice what we’ve learned so far. You can either continue from the same RMarkdown as yesterday, or begin a new one. Here’s what to do: Clear your workspace (Session &gt; Restart R) New File &gt; R Markdown…, save as something other than gapminder-wrangle.Rmd and delete irrelevant info, or just continue using gapminder-wrangle.Rmd I’m going to write this in my R Markdown file: Data wrangling with `tidyr`, which is part of the tidyverse. We are going to tidy some data! 7.3.2 load tidyverse (which has tidyr inside) First load tidyr in an R chunk. You already have installed the tidyverse, so you should be able to just load it like this (using the comment so you can run install.packages(&quot;tidyverse&quot;) easily if need be): library(tidyverse) # install.packages(&quot;tidyverse&quot;) 7.4 gather() data from wide to long format Read in the data from GitHub. Remember, you need to click on the ‘Raw’ button first so you can read it directly. Let’s also read in the gapminder data from yesterday so that we can use it to compare later on. ## wide format gap_wide &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/gapminder_wide.csv&#39;) ## yesterday&#39;s format gapminder &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/gapminder.csv&#39;) Let’s have a look: head(gap_wide) str(gap_wide) While wide format is nice for data entry, it’s not nice for calculations. Some of the columns are a mix of variable (e.g. “gdpPercap”) and data (“1952”). What if you were asked for the mean population after 1990 in Algeria? Possible, but ugly. But we know it doesn’t need to be so ugly. Let’s tidy it back to the format we’ve been using. Question: let’s talk this through together. If we’re trying to turn the gap_wide format into gapminder format, what structure does it have that we like? And what do we want to change? We like the continent and country columns. We won’t want to change those. We want 1 column identifying the variable name (tidyr calls this a ‘key’), and 1 column for the data (tidyr calls this the ’value’). We actually want 3 different columns for variable: gdpPercap, lifeExp, and pop. We would like year as a separate column. Let’s get it to long format. We’ll have to do this in 2 steps. The first step is to take all of those column names (e.g. lifeExp_1970) and make them a variable in a new column, and transfer the values into another column. Let’s learn by doing: Let’s have a look at gather()’s help: ?gather Question: What is our key-value pair? We need to name two new variables in the key-value pair, one for the key, one for the value. It can be hard to wrap your mind around this, so let’s give it a try. Let’s name them obstype_year and obs_values. Here’s the start of what we’ll do: gap_long &lt;- gap_wide %&gt;% gather(key = obstype_year, value = obs_values) Although we were already planning to inspect our work, let’s definitely do it now: str(gap_long) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 5396 obs. of 2 variables: ## $ obstype_year: chr &quot;continent&quot; &quot;continent&quot; &quot;continent&quot; &quot;continent&quot; ... ## $ obs_values : chr &quot;Africa&quot; &quot;Africa&quot; &quot;Africa&quot; &quot;Africa&quot; ... head(gap_long) ## # A tibble: 6 x 2 ## obstype_year obs_values ## &lt;chr&gt; &lt;chr&gt; ## 1 continent Africa ## 2 continent Africa ## 3 continent Africa ## 4 continent Africa ## 5 continent Africa ## 6 continent Africa tail(gap_long) ## # A tibble: 6 x 2 ## obstype_year obs_values ## &lt;chr&gt; &lt;chr&gt; ## 1 pop_2007 9031088 ## 2 pop_2007 7554661 ## 3 pop_2007 71158647 ## 4 pop_2007 60776238 ## 5 pop_2007 20434176 ## 6 pop_2007 4115771 We have reshaped our dataframe but this new format isn’t really what we wanted. What went wrong? Notice that it didn’t know that we wanted to keep continent and country untouched; we need to give it more information about which columns we want reshaped. We can do this in several ways. One way is to identify the columns is by name. Listing them explicitly can be a good approach if there are just a few. But in our case we have 30 columns. I’m not going to list them out here since there is way too much potential for error if I tried to list gdpPercap_1952, gdpPercap_1957, gdpPercap_1962 and so on. But we could use some of dplyr’s awesome helper functions — because we expect that there is a better way to do this! gap_long &lt;- gap_wide %&gt;% gather(key = obstype_year, value = obs_values, dplyr::starts_with(&#39;pop&#39;), dplyr::starts_with(&#39;lifeExp&#39;), dplyr::starts_with(&#39;gdpPercap&#39;)) #here i&#39;m listing all the columns to use in gather str(gap_long) head(gap_long) tail(gap_long) Success! And there is another way that is nice to use if your columns don’t follow such a structured pattern: you can exclude the columns you don’t want. gap_long &lt;- gap_wide %&gt;% gather(key = obstype_year, value = obs_values, -continent, -country) str(gap_long) head(gap_long) tail(gap_long) To recap: Inside gather() we first name the new column for the new ID variable (obstype_year), the name for the new amalgamated observation variable (obs_value), then the names of the old observation variable. We could have typed out all the observation variables, but as in the select() function (see dplyr lesson), we can use the starts_with() argument to select all variables that starts with the desired character string. Gather also allows the alternative syntax of using the - symbol to identify which variables are not to be gathered (i.e. ID variables). OK, but we’re not done yet. obstype_year actually contains two pieces of information, the observation type (pop,lifeExp, or gdpPercap) and the year. We can use the separate() function to split the character strings into multiple variables. ?separate –&gt; the main arguments are separate(data, col, into, sep ...). So we need to specify which column we want separated, name the new columns that we want to create, and specify what we want it to separate by. Since the obstype_year variable has observation types and years separated by a _, we’ll use that. gap_long &lt;- gap_wide %&gt;% gather(key = obstype_year, value = obs_values, -continent, -country) %&gt;% separate(obstype_year, into = c(&#39;obs_type&#39;,&#39;year&#39;), sep = &quot;_&quot;, convert = TRUE) #this ensures that the year column is an integer rather than a character No warning messages…still we inspect: str(gap_long) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 5112 obs. of 5 variables: ## $ continent : chr &quot;Africa&quot; &quot;Africa&quot; &quot;Africa&quot; &quot;Africa&quot; ... ## $ country : chr &quot;Algeria&quot; &quot;Angola&quot; &quot;Benin&quot; &quot;Botswana&quot; ... ## $ obs_type : chr &quot;gdpPercap&quot; &quot;gdpPercap&quot; &quot;gdpPercap&quot; &quot;gdpPercap&quot; ... ## $ year : int 1952 1952 1952 1952 1952 1952 1952 1952 1952 1952 ... ## $ obs_values: num 2449 3521 1063 851 543 ... head(gap_long) ## # A tibble: 6 x 5 ## continent country obs_type year obs_values ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Africa Algeria gdpPercap 1952 2449. ## 2 Africa Angola gdpPercap 1952 3521. ## 3 Africa Benin gdpPercap 1952 1063. ## 4 Africa Botswana gdpPercap 1952 851. ## 5 Africa Burkina Faso gdpPercap 1952 543. ## 6 Africa Burundi gdpPercap 1952 339. tail(gap_long) ## # A tibble: 6 x 5 ## continent country obs_type year obs_values ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Europe Sweden pop 2007 9031088 ## 2 Europe Switzerland pop 2007 7554661 ## 3 Europe Turkey pop 2007 71158647 ## 4 Europe United Kingdom pop 2007 60776238 ## 5 Oceania Australia pop 2007 20434176 ## 6 Oceania New Zealand pop 2007 4115771 Excellent. This is long format: every row is a unique observation. Yay! 7.5 Plot long format data The long format is the preferred format for plotting with ggplot2. Let’s look at an example by plotting just Canada’s life expectancy. canada_df &lt;- gap_long %&gt;% filter(obs_type == &quot;lifeExp&quot;, country == &quot;Canada&quot;) ggplot(canada_df, aes(x = year, y = obs_values)) + geom_line() We can also look at all countries in the Americas: life_df &lt;- gap_long %&gt;% filter(obs_type == &quot;lifeExp&quot;, continent == &quot;Americas&quot;) ggplot(life_df, aes(x = year, y = obs_values, color = country)) + geom_line() 7.5 Exercise Using gap_long, calculate and plot the the mean life expectancy for each continent over time from 1982 to 2007. Give your plot a title and assign x and y labels. Hint: do this in two steps. First, do the logic and calculations using dplyr::group_by() and dplyr::summarize(). Second, plot using ggplot(). STOP: Knit the R Markdown file and sync to Github (pull, stage, commit, push) # solution (no peeking!) continents &lt;- gap_long %&gt;% filter(obs_type == &quot;lifeExp&quot;, year &gt; 1980) %&gt;% group_by(continent, year) %&gt;% summarize(mean_le = mean(obs_values)) %&gt;% ungroup() ggplot(data = continents, aes(x = year, y = mean_le, color = continent)) + geom_line() + labs(title = &quot;Mean life expectancy&quot;, x = &quot;Year&quot;, y = &quot;Age (years)&quot;) ## Additional customization ggplot(data = continents, aes(x = year, y = mean_le, color = continent)) + geom_line() + labs(title = &quot;Mean life expectancy&quot;, x = &quot;Year&quot;, y = &quot;Age (years)&quot;, color = &quot;Continent&quot;) + theme_classic() + scale_fill_brewer(palette = &quot;Blues&quot;) 7.6 spread() The function spread() is used to transform data from long to wide format Alright! Now just to double-check our work, let’s use the opposite of gather() to spread our observation variables back to the original format with the aptly named spread(). You pass spread() the key and value pair, which is now obs_type and obs_values. gap_normal &lt;- gap_long %&gt;% spread(obs_type, obs_values) No warning messages is good…but still let’s check: dim(gap_normal) dim(gapminder) names(gap_normal) names(gapminder) Now we’ve got a dataframe gap_normal with the same dimensions as the original gapminder. 7.6 Exercise Convert gap_long all the way back to gap_wide. Hint: Do this in 2 steps. First, create appropriate labels for all our new variables (variable_year combinations) with the opposite of separate: tidyr::unite(). Second, spread() that variable_year column into wider format. Knit the R Markdown file and sync to Github (pull, stage, commit, push) 7.6.1 Answer (no peeking) head(gap_long) # remember the columns gap_wide_new &lt;- gap_long %&gt;% # first unite obs_type and year into a new column called var_names. Separate by _ unite(col = var_names, obs_type, year, sep = &quot;_&quot;) %&gt;% # then spread var_names out by key-value pair. spread(key = var_names, value = obs_values) str(gap_wide_new) 7.7 clean up and save your .Rmd Spend some time cleaning up and saving gapminder-wrangle.Rmd Restart R. In RStudio, use Session &gt; Restart R. Otherwise, quit R with q() and re-launch it. This morning’s .Rmd could look something like this: ## load tidyr (in tidyverse) library(tidyverse) # install.packages(&quot;tidyverse&quot;) ## load wide data gap_wide &lt;- read.csv(&#39;https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/gapminder_wide.csv&#39;) head(gap_wide) str(gap_wide) ## practice tidyr::gather() wide to long gap_long &lt;- gap_wide %&gt;% gather(key = obstype_year, value = obs_values, -continent, -country) # or gap_long &lt;- gap_wide %&gt;% gather(key = obstype_year, value = obs_values, dplyr::starts_with(&#39;pop&#39;), dplyr::starts_with(&#39;lifeExp&#39;), dplyr::starts_with(&#39;gdpPercap&#39;)) ## gather() and separate() to create our original gapminder gap_long &lt;- gap_wide %&gt;% gather(key = obstype_year, value = obs_values, -continent, -country) %&gt;% separate(obstype_year, into = c(&#39;obs_type&#39;,&#39;year&#39;), sep=&quot;_&quot;) ## practice: can still do calculations in long format gap_long %&gt;% group_by(continent, obs_type) %&gt;% summarize(means = mean(obs_values)) ## spread() from normal to wide gap_normal &lt;- gap_long %&gt;% spread(obs_type, obs_values) %&gt;% select(country, continent, year, lifeExp, pop, gdpPercap) ## check that all.equal() all.equal(gap_normal,gapminder) ## unite() and spread(): convert gap_long to gap_wide head(gap_long) # remember the columns gap_wide_new &lt;- gap_long %&gt;% # first unite obs_type and year into a new column called var_names. Separate by _ unite(col = var_names, obs_type, year, sep = &quot;_&quot;) %&gt;% # then spread var_names out by key-value pair. spread(key = var_names, value = obs_values) str(gap_wide_new) 7.7.1 complete() One of the coolest functions in tidyr is the function complete(). Jarrett Byrnes has written up a great blog piece showcasing the utility of this function so I’m going to use that example here. We’ll start with an example dataframe where the data recorder enters the Abundance of two species of kelp, Saccharina and Agarum in the years 1999, 2000 and 2004. kelpdf &lt;- data.frame( Year = c(1999, 2000, 2004, 1999, 2004), Taxon = c(&quot;Saccharina&quot;, &quot;Saccharina&quot;, &quot;Saccharina&quot;, &quot;Agarum&quot;, &quot;Agarum&quot;), Abundance = c(4,5,2,1,8) ) kelpdf Jarrett points out that Agarum is not listed for the year 2000. Does this mean it wasn’t observed (Abundance = 0) or that it wasn’t recorded (Abundance = NA)? Only the person who recorded the data knows, but let’s assume that the this means the Abundance was 0 for that year. We can use the complete() function to make our dataset more complete. kelpdf %&gt;% complete(Year, Taxon) This gives us an NA for Agarum in 2000, but we want it to be a 0 instead. We can use the fill argument to assign the fill value. kelpdf %&gt;% complete(Year, Taxon, fill = list(Abundance = 0)) Now we have what we want. Let’s assume that all years between 1999 and 2004 that aren’t listed should actually be assigned a value of 0. We can use the full_seq() function from tidyr to fill out our dataset with all years 1999-2004 and assign Abundance values of 0 to those years &amp; species for which there was no observation. kelpdf %&gt;% complete(Year = full_seq(Year, period = 1), Taxon, fill = list(Abundance = 0)) 7.8 Other links Tidying up Data - Env Info - Rmd Data wrangling with dplyr and tidyr - Tyler Clavelle &amp; Dan Ovando - Rmd "],
["programming.html", "Chapter 8 Programming in R 8.1 Objectives &amp; Resources 8.2 Analysis plan 8.3 Create an R script 8.4 Automation with for loops 8.5 Conditional statements with if and else 8.6 More R! 8.7 Ideas for Extended Analysis 2", " Chapter 8 Programming in R 8.1 Objectives &amp; Resources Now we are going to build a little analysis. We will learn to automate our analyses with a for loop. We will make figures, and save them each with automated labeling. Then, we will join data from different files and conditionally label them with if/else statements. 8.1.1 Objectives create an R script for loops joining data if statements 8.2 Analysis plan ## Error in library(gapminder): there is no package called &#39;gapminder&#39; OK, here is the plan for our analysis. We want to plot the gdpPercap for each country in the gapminder data frame. So that’s 142 separate plots! We will automate this, labeling each one with its name and saving it in a folder called figures. We will learn a bunch of things as we go. 8.3 Create an R script OK, now, we are going to create an R script. What is an R script? It’s a text file with a .R extension. We’ve been writing R code in R Markdown files so far; R scripts are just R code without the Markdown along with it. Go to File &gt; New File &gt; R Script (or click the green plus in the top left corner). Let’s start off with a few comments so that we know what it is for, and save it: ## gapminder-analysis.R ## analysis with gapminder data ## J Lowndes lowndes@nceas.ucsb.edu We’ll be working with the gapminder data again so let’s read it in here: ## load libraries library(tidyverse) ## read in gapminder data gapminder &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/gapminder.csv&#39;) Remember, like in R Markdown, hitting return does not execute this command. To execute it, we need to get what we typed in the script down into the console. Here is how we can do that: copy-paste this line into the console. select the line (or simply put the cursor there), and click ‘Run’. This is available from the bar above the script (green arrow) the menu bar: Code &gt; Run Selected Line(s) keyboard shortcut: command-return source the script, which means running the whole thing. This is also great for to see if there are any typos in your code that you’ve missed. You can do this by: clicking Source (blue arrow in the bar above the script). typing source('gapminder-analysis.R') in the console (or from another R file!!!). 8.4 Automation with for loops Our plan is to plot gdpPercap for each country. This means that we want to do the same operation (plotting gdpPercap) on a bunch of different things (countries). Yesterday we learned the dplyr’s group_by() function, and this is super powerful to automate through groups. But there are things that you may not want to do with group_by(), like plotting. So we will use a for loop. Let’s start off with what this would look like for just one country. I’m going to demonstrate with Afghanistan: ## filter the country to plot gap_to_plot &lt;- gapminder %&gt;% filter(country == &quot;Afghanistan&quot;) ## plot my_plot &lt;- ggplot(data = gap_to_plot, aes(x = year, y = gdpPercap)) + geom_point() + labs(title = &quot;Afghanistan&quot;) Let’s actually give this a better title than just the country name. Let’s use the base::paste() function from to paste two strings together so that the title is more descriptive. Use ?paste to see what the “sep” variable does. ## filter the country to plot gap_to_plot &lt;- gapminder %&gt;% filter(country == &quot;Afghanistan&quot;) ## plot my_plot &lt;- ggplot(data = gap_to_plot, aes(x = year, y = gdpPercap)) + geom_point() + ## add title and save labs(title = paste(&quot;Afghanistan&quot;, &quot;GDP per capita&quot;, sep = &quot; &quot;)) And as a last step, let’s save this figure. ## filter the country to plot gap_to_plot &lt;- gapminder %&gt;% filter(country == &quot;Afghanistan&quot;) ## plot my_plot &lt;- ggplot(data = gap_to_plot, aes(x = year, y = gdpPercap)) + geom_point() + ## add title and save labs(title = paste(&quot;Afghanistan&quot;, &quot;GDP per capita&quot;, sep = &quot; &quot;)) ggsave(filename = &quot;Afghanistan_gdpPercap.png&quot;, plot = my_plot) OK. So we can check our repo in the file pane (bottom right of RStudio) and see the generated figure: 8.4.1 Thinking ahead: cleaning up our code Now, in our code above, we’ve had to write out “Afghanistan” several times. This makes it not only typo-prone as we type it each time, but if we wanted to plot another country, we’d have to write that in 3 places too. It is not setting us up for an easy time in our future, and thinking ahead in programming is something to keep in mind. Instead of having “Afghanistan” written 3 times, let’s instead create an object that we will assign to “Afghanistan”. We won’t name our object “country” because that’s a column header with gapminder, and will just confuse us. Let’s make it distinctive: let’s write cntry (country without vowels): ## create country variable cntry &lt;- &quot;Afghanistan&quot; Now, we can replace each &quot;Afghanistan&quot; with our variable cntry. We will have to introduce a paste statement here too, and we want to separate by nothing (&quot;&quot;). Note: there are many ways to create the filename, and we are doing it this way for a specific reason right now. ## create country variable cntry &lt;- &quot;Afghanistan&quot; ## filter the country to plot gap_to_plot &lt;- gapminder %&gt;% filter(country == cntry) ## plot my_plot &lt;- ggplot(data = gap_to_plot, aes(x = year, y = gdpPercap)) + geom_point() + ## add title and save labs(title = paste(cntry, &quot;GDP per capita&quot;, sep = &quot; &quot;)) ## note: there are many ways to create filenames with paste() or file.path(); we are doing this way for a reason. ggsave(filename = paste(cntry, &quot;_gdpPercap.png&quot;, sep = &quot;&quot;), plot = my_plot) Let’s run this. Great! it saved our figure (I can tell this because the timestamp in the Files pane has updated!) 8.4.2 For loop basic structure Now, how about if we want to plot not only Afghanistan, but other countries as well? There wasn’t actually that much code needed to get us here, but we definitely do not want to copy this for every country. Even if we copy-pasted and switched out the country assigned to the cntry variable, it would be very typo-prone. Plus, what if you wanted to instead plot lifeExp? You’d have to remember to change it each time…it gets messy quick. Better with a for loop. This will let us cycle through and do what we want to each thing in turn. If you want to iterate over a set of values, and perform the same operation on each, a for loop will do the job. Sit back and watch me for a few minutes while we develop the for loop. Then we’ll give you time to do this on your computers as well. The basic structure of a for loop is: for( each item in set of items ){ do a thing } Note the ( ) and the { }. We talk about iterating through each item in the for loop, which makes each item an iterator. So looking back at our Afghanistan code: all of this is pretty much the “do a thing” part. And we can see that there are only a few places that are specific to Afghanistan. If we could make those places not specific to Afghanistan, we would be set. Let’s paste from what we had before, and modify it. I’m also going to use RStudio’s indentation help to indent the lines within the for loop by highlighting the code in this chunk and going to Code &gt; Reindent Lines (shortcut: command I) ## create country variable cntry &lt;- &quot;Afghanistan&quot; for (each cntry in a list of countries ) { ## filter the country to plot gap_to_plot &lt;- gapminder %&gt;% filter(country == cntry) ## plot my_plot &lt;- ggplot(data = gap_to_plot, aes(x = year, y = gdpPercap)) + geom_point() + ## add title and save labs(title = paste(cntry, &quot;GDP per capita&quot;, sep = &quot; &quot;)) ggsave(filename = paste(cntry, &quot;_gdpPercap.png&quot;, sep = &quot;&quot;), plot = my_plot) } 8.4.3 Executable for loop! OK. So let’s start with the beginning of the for loop. We want a list of countries that we will iterate through. We can do that by adding this code before the for loop. ## create a list of countries country_list &lt;- c(&quot;Albania&quot;, &quot;Fiji&quot;, &quot;Spain&quot;) for ( cntry in country_list ) { ## filter the country to plot gap_to_plot &lt;- gapminder %&gt;% filter(country == cntry) ## plot my_plot &lt;- ggplot(data = gap_to_plot, aes(x = year, y = gdpPercap)) + geom_point() + ## add title and save labs(title = paste(cntry, &quot;GDP per capita&quot;, sep = &quot; &quot;)) ggsave(filename = paste(cntry, &quot;_gdpPercap.png&quot;, sep = &quot;&quot;), plot = my_plot) } At this point, we do have a functioning for loop. For each item in the country_list, the for loop will iterate over the code within the { }, changing cntry each time as it goes through the list. And we can see it works because we can see them appear in the files pane at the bottom right of RStudio! Great! And it doesn’t matter if we just use these three countries or all the countries–let’s try it. But first let’s create a figure directory and make sure it saves there since it’s going to get out of hand quickly. We could do this from the Finder/Windows Explorer, or from the “Files” pane in RStudio by clicking “New Folder” (green plus button). But we are going to do it in R. A folder is called a directory: dir.create(&quot;figures&quot;) ## create a list of countries country_list &lt;- unique(gapminder$country) # ?unique() returns the unique values for( cntry in country_list ){ ## filter the country to plot gap_to_plot &lt;- gapminder %&gt;% filter(country == cntry) ## plot my_plot &lt;- ggplot(data = gap_to_plot, aes(x = year, y = gdpPercap)) + geom_point() + ## add title and save labs(title = paste(cntry, &quot;GDP per capita&quot;, sep = &quot; &quot;)) ## add the figures/ folder ggsave(filename = paste(&quot;figures/&quot;, cntry, &quot;_gdpPercap.png&quot;, sep = &quot;&quot;)), plot = my_plot) } So that took a little longer than just the 3, but still super fast. For loops are sometimes just the thing you need to iterate over many things in your analyses. 8.4.4 Clean up our repo OK we now have 142 figures that we just created. They exist locally on our computer, and we have the code to recreate them anytime. But, we don’t really need to push them to GitHub. Let’s delete the figures/ folder and see it disappear from the Git tab. 8.4.5 Your turn Modify our for loop so that it: loops through countries in Europe only plots the cumulative mean gdpPercap (Hint: Use the Data Wrangling Cheatsheet!) saves them to a new subfolder inside the (recreated) figures folder called “Europe”. Sync to GitHub 8.4.5.1 Answer No peeking! dir.create(&quot;figures&quot;) dir.create(&quot;figures/Europe&quot;) ## create a list of countries. Calculations go here, not in the for loop gap_europe &lt;- gapminder %&gt;% filter(continent == &quot;Europe&quot;) %&gt;% mutate(gdpPercap_cummean = dplyr::cummean(gdpPercap)) country_list &lt;- unique(gap_europe$country) # ?unique() returns the unique values for( cntry in country_list ){ # (cntry = country_list[1]) ## filter the country to plot gap_to_plot &lt;- gap_europe %&gt;% filter(country == cntry) ## add a print message to see what&#39;s plotting print(paste(&quot;Plotting&quot;, cntry)) ## plot my_plot &lt;- ggplot(data = gap_to_plot, aes(x = year, y = gdpPercap_cummean)) + geom_point() + ## add title and save labs(title = paste(cntry, &quot;GDP per capita&quot;, sep = &quot; &quot;)) ggsave(filename = paste(&quot;figures/Europe/&quot;, cntry, &quot;_gdpPercap_cummean.png&quot;, sep = &quot;&quot;)), plot = my_plot) } Notice how we put the calculation for cummean() outside the for loop. It could have gone inside, but it’s an operation that could be done just one time before hand (outside the loop) rather than multiple times as you go (inside the for loop). 8.5 Conditional statements with if and else Often when we’re coding we want to control the flow of our actions. This can be done by setting actions to occur only if a condition or a set of conditions are met. In R and other languages, these are called “if statements”. 8.5.1 if statement basic structure # if if (condition is true) { do something } # if ... else if (condition is true) { do something } else { # that is, if the condition is false, do something different } Let’s bring this concept into our for loop for Europe that we’ve just done. What if we want to add the label “Estimated” to countries that were estimated? Here’s what we’d do. First, import csv file with information on whether data was estimated or reported, and join to gapminder dataset: est &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/OHI-Science/data-science-training/master/data/countries_estimated.csv&#39;) gapminder_est &lt;- left_join(gapminder, est) dir.create(&quot;figures&quot;) dir.create(&quot;figures/Europe&quot;) ## create a list of countries gap_europe &lt;- gapminder_est %&gt;% ## use instead of gapminder filter(continent == &quot;Europe&quot;) %&gt;% mutate(gdpPercap_cummean = dplyr::cummean(gdpPercap)) country_list &lt;- unique(gap_europe$country) for( cntry in country_list ){ # (cntry = country_list[1]) ## filter the country to plot gap_to_plot &lt;- gap_europe %&gt;% filter(country == cntry) ## add a print message print(paste(&quot;Plotting&quot;, cntry)) ## plot my_plot &lt;- ggplot(data = gap_to_plot, aes(x = year, y = gdpPercap_cummean)) + geom_point() + ## add title and save labs(title = paste(cntry, &quot;GDP per capita&quot;, sep = &quot; &quot;)) ## if estimated, add that as a subtitle. if (gap_to_plot$estimated == &quot;yes&quot;) { ## add a print statement just to check print(paste(cntry, &quot;data are estimated&quot;)) my_plot &lt;- my_plot + labs(sutbtitle(&quot;Estimated data&quot;)) } # Warning message: # In if (gap_to_plot$estimated == &quot;yes&quot;) { : # the condition has length &gt; 1 and only the first element will be used ggsave(filename = paste(&quot;figures/Europe/&quot;, cntry, &quot;_gdpPercap_cummean.png&quot;, sep = &quot;&quot;), plot = my_plot) } This worked, but we got a warning message with the if statement. This is because if we look at gap_to_plot$estimated, it is many “yes”s or “no”s, and the if statement works just on the first one. We know that if any are yes, all are yes, but you can imagine that this could lead to problems down the line if you didn’t know that. So let’s be explicit: 8.5.2 Executable if statement dir.create(&quot;figures&quot;) dir.create(&quot;figures/Europe&quot;) ## create a list of countries gap_europe &lt;- gapminder_est %&gt;% ## use instead of gapminder filter(continent == &quot;Europe&quot;) %&gt;% mutate(gdpPercap_cummean = dplyr::cummean(gdpPercap)) country_list &lt;- unique(gap_europe$country) for( cntry in country_list ){ # (cntry = country_list[1]) ## filter the country to plot gap_to_plot &lt;- gap_europe %&gt;% filter(country == cntry) ## add a print message print(paste(&quot;Plotting&quot;, cntry)) ## plot my_plot &lt;- ggplot(data = gap_to_plot, aes(x = year, y = gdpPercap_cummean)) + geom_point() + ## add title and save labs(title = paste(cntry, &quot;GDP per capita&quot;, sep = &quot; &quot;)) ## if estimated, add that as a subtitle. if (any(gap_to_plot$estimated == &quot;yes&quot;)) { # any() will return a single TRUE or FALSE print(paste(cntry, &quot;data are estimated&quot;)) my_plot &lt;- my_plot + labs(subtitle = &quot;Estimated data&quot;) } ggsave(filename = paste(&quot;figures/Europe/&quot;, cntry, &quot;_gdpPercap_cummean.png&quot;, sep = &quot;&quot;), plot = my_plot) } OK so this is working as we expect! Note that we do not need an else statement above, because we only want to do something (add a subtitle) if one condition is met. But what if we want to add a different subtitle based on another condition, say where the data are reported, to be extra explicit about it? 8.5.3 Executable if/else statement dir.create(&quot;figures&quot;) dir.create(&quot;figures/Europe&quot;) ## create a list of countries gap_europe &lt;- gapminder_est %&gt;% ## use instead of gapminder filter(continent == &quot;Europe&quot;) %&gt;% mutate(gdpPercap_cummean = dplyr::cummean(gdpPercap)) country_list &lt;- unique(gap_europe$country) for( cntry in country_list ){ # (cntry = country_list[1]) ## filter the country to plot gap_to_plot &lt;- gap_europe %&gt;% filter(country == cntry) ## add a print message print(paste(&quot;Plotting&quot;, cntry)) ## plot my_plot &lt;- ggplot(data = gap_to_plot, aes(x = year, y = gdpPercap_cummean)) + geom_point() + ## add title and save labs(title = paste(cntry, &quot;GDP per capita&quot;, sep = &quot; &quot;)) ## if estimated, add that as a subtitle. if (any(gap_to_plot$estimated == &quot;yes&quot;)) { # any() will return a single TRUE or FALSE print(paste(cntry, &quot;data are estimated&quot;)) my_plot &lt;- my_plot + labs(subtitle = &quot;Estimated data&quot;) } else { my_plot &lt;- my_plot + labs(subtitle = &quot;Reported data&quot;) print(paste(cntry, &quot;data are reported&quot;)) } ggsave(filename = paste(&quot;figures/Europe/&quot;, cntry, &quot;_gdpPercap_cummean.png&quot;, sep = &quot;&quot;), plot = my_plot) } Note that this works because we know there are only two conditions, Estimated == yes and Estimated == no. In the first if statement we asked for estimated data, and the else condition gives us everything else (which we know is reported). We can be explicit about setting these conditions in the else clause by instead using an else if statement. Below is how you would construct this in your for loop, similar to above: if (any(gap_to_plot$estimated == &quot;yes&quot;)) { # any() will return a single TRUE or FALSE print(paste(cntry, &quot;data are estimated&quot;)) my_plot &lt;- my_plot + labs(subtitle = &quot;Estimated data&quot;) } else if (any(gap_to_plot$estimated == &quot;no&quot;)){ my_plot &lt;- my_plot + labs(subtitle = &quot;Reported data&quot;) print(paste(cntry, &quot;data are reported&quot;)) } This construction is necessary if you have more than two conditions to test for. 8.6 More R! With just a little bit of time left, here are some things that you can look into more on your own. 8.6.1 Importing and Installing Here are some really helpful packages for you to work with: Remember you’ll use install.packages(&quot;package-name-in-quotes&quot;) to install from CRAN. readr to read in .csv files readxl to read in Excel files stringr to work with strings lubridate to work with dates You are also able to install packages directly with Github, using the devtools package. Then, instead of install.packages(), you’ll use devtools::install_github(). And you can create your own packages when you’re ready. Read http://r-pkgs.had.co.nz/ to learn how! 8.6.2 Organization and workflows set up a folder for figs, intermediate analyses, final outputs, figures 8.6.3 Getting help You’ll soon have questions that are outside the scope of this workshop, how do you find answers? end with a ton of resources: https://peerj.com/collections/50-practicaldatascistats/ 8.7 Ideas for Extended Analysis 2 stringr() http://r4ds.had.co.nz/strings.html "],
["collaborating.html", "Chapter 9 Collaborating with GitHub 9.1 Objectives &amp; Resources 9.2 Create repo (Partner 1) 9.3 Create a gh-pages branch (Partner 1) 9.4 Give your collaborator administration privileges (Partner 1 and 2) 9.5 Clone to a new Rproject (Partner 1) 9.6 Clone to a new Rproject (Partner 2) 9.7 Edit a file and sync (Partner 2) 9.8 State of the Repository 9.9 Merge conflicts 9.10 How do you avoid merge conflicts? 9.11 Create your collaborative website 9.12 Your turn 9.13 Explore on GitHub.com 9.14 NYC flights exploration 9.15 Your turn", " Chapter 9 Collaborating with GitHub 9.1 Objectives &amp; Resources The collaborative power of GitHub and RStudio is really game changing. So far we’ve been collaborating with our most important collaborator: ourselves. But, we are lucky that in science we have so many other collaborators, so let’s learn how to accelerate our collaborations with them through GitHub! We are going to teach you the simplest way to collaborate with someone, which is for both of you to have privileges to edit and add files to a repository. GitHub is built for software developer teams, and there is a lot of features that limit who can directly edit files, but we don’t need to start there. We will do this all with a partner, and we’ll walk through some things all together, and then give you a chance to work with your collaborator on your own. 9.1.1 Objectives We are going to create a website with a collaborator! create a new repo and give permission to a collaborator open as a new RStudio project! collaborate with a partner explore github.com blame, history, issues 9.2 Create repo (Partner 1) Team up with a partner sitting next to you. Partner 1 will create a new repository. We will do this in the same way that we did in Chapter 4: Create a repository on Github.com. 9.3 Create a gh-pages branch (Partner 1) We aren’t going to talk about branches very much, but they are a powerful feature of git/GitHub. I think of it as creating a copy of your work that becomes a parallel universe that you can modify safely because it’s not affecting your original work. And then you can choose to merge the universes back together if and when you want. By default, when you create a new repo you begin with one branch, and it is named master. When you create new branches, you can name them whatever you want. However, if you name one gh-pages (all lowercase, with a - and no spaces), this will let you create a website. And that’s our plan. So, Partner 1, do this to create a gh-pages branch: On the homepage for your repo on GitHub.com, click the button that says “Branch:master”. Here, you can switch to another branch (right now there aren’t any others besides master), or create one by typing a new name. Let’s type gh-pages. Let’s also change gh-pages to the default branch and delete the master branch: this will be a one-time-only thing that we do here: First click to control branches: And then click to change the default branch to gh-pages. I like to then delete the master branch when it has the little red trash can next to it. It will make you confirm that you really want to delete it, which I do! 9.4 Give your collaborator administration privileges (Partner 1 and 2) Now, Partner 1, go into Settings &gt; Collaborators &gt; enter Partner 2’s (your collaborator’s) username. Partner 2 then needs to check their email and accept as a collaborator. Notice that your collaborator has “Push access to the repository” (highlighted below): 9.5 Clone to a new Rproject (Partner 1) Now let’s have Partner 1 clone the repository to their local computer. We’ll do this through RStudio like we did before (see Chapter 4: Clone your repository using RStudio), but with a final additional step before hitting “Create Project”: select “Open in a new Session”. Opening this Project in a new Session opens up a new world of awesomeness from RStudio. Having different RStudio project sessions allows you to keep your work separate and organized. So you can collaborate with this collaborator on this repository while also working on your other repository from this morning. I tend to have a lot of projects going at one time: Have a look in your git tab. Like we saw this morning, when you first clone a repo through RStudio, RStudio will add an .Rproj file to your repo. And if you didn’t add a .gitignore file when you originally created the repo on GitHub.com, RStudio will also add this for you. So, Partner 1, let’s go ahead and sync this back to GitHub.com. Remember: Let’s confirm that this was synced by looking at GitHub.com again. You may have to refresh the page, but you should see this commit where you added the .Rproj file. 9.6 Clone to a new Rproject (Partner 2) Now it’s Partner 2’s turn! Partner 2, clone this repository following the same steps that Partner 1 just did. When you clone it, RStudio should not create any new files — why? Partner 1 already created and pushed eht the .Rproj and .gitignore files so they already exist in the repo. 9.7 Edit a file and sync (Partner 2) Let’s have Partner 2 add some information to the README.md. Let’s have them write: Collaborators: - Partner 2&#39;s name When we save the README.md, And now let’s sync back to GitHub. When we inspect on GitHub.com, click to view all the commits, you’ll see commits logged from both Partner 1 and 2! Question: Would you still be able clone a repository that you are not a collaborator on? What do you think would happen? Try it! Can you sync back? 9.8 State of the Repository OK, so where do things stand right now? GitHub.com has the most recent versions of all the repository’s files. Partner 2 also has these most recent versions locally. How about Partner 1? Partner 1 does not have the most recent versions of everything on their computer. Question: How can we change that? Or how could we even check? Answer: PULL. Let’s have Partner 1 go back to RStudio and Pull. If their files aren’t up-to-date, this will pull the most recent versions to their local computer. And if they already did have the most recent versions? Well, pulling doesn’t cost anything (other than an internet connection), so if everything is up-to-date, pulling is fine too. I recommend pulling every time you come back to a collaborative repository. Whether you haven’t opened RStudio in a month or you’ve just been away for a lunch break, pull. It might not be necessary, but it can save a lot of heartache later. 9.9 Merge conflicts What kind of heartache are we talking about? Let’s explore. Stop and watch me create and solve a merge conflict with my Partner 2, and then you will have time to recreate this with your partner. Here’s what I am going to do: Within a file, GitHub tracks changes line-by-line. So you can also have collaborators working on different lines within the same file and GitHub will be able to weave those changes into each other – that’s it’s job! It’s when you have collaborators working on the same lines within the same file that you can have merge conflicts. Merge conflicts can be frustrating, but they are actually trying to help you (kind of like R’s error messages). They occur when GitHub can’t make a decision about what should be on a particular line and needs a human (you) to decide. And this is good – you don’t want GitHub to decide for you, it’s important that you make that decision. So let’s test this. Let’s have both Partners 1 and 2 go to RStudio and pull so you have the most recent versions of all your files. Now, Partners 1 and 2, both go to the README, and on Line 7, write something, anything. I’m not going to give any examples because I want both Partners to write something different. And be sure to save the README. OK. Now, let’s have Partner 2 sync: pull, stage, commit, push. Great. Now, when Partner 2 is done, let’s have Partner 1 (me) try. Partner 1: pull —- Error! Merge conflict! So Partner 1 is not allowed to pull, it failed. GitHub is protecting Partner 1 because if they did successfully pull, their work would be overwritten by whatever Partner 2 had written. So GitHub is going to make a human (Partner 1 in this case) decide. GitHub says, either commit this work first, or “stash it” (I interpret that as saving a copy of the README in another folder somewhere outside of this GitHub repository). Let’s follow their advice and have Partner 1 commit. Great. Now let’s pull again. Still not happy! OK, actually, we’re just moving along this same problem that we know that we’ve created: Both Partner 1 and 2 have both added new information to the same line. You can see that the pop-up box is saying that there is a CONFLICT and the merge has not happened. OK. We can close that window and inspect. Notice that in the git tab, there are orange Us; this means that there is an unresolved conflict, and it is not staged with a check anymore because modifications have occurred to the file since it has been staged. Let’s look at the README file itself. We got a preview in the diff pane that there is some new text going on in our README file: &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Julie is collaborating on this README. ======= **Jamie is adding lines here.** &gt;&gt;&gt;&gt;&gt;&gt;&gt; 05a189b23372f0bdb5b42630f8cb318003cee19b In this example, Partner 1 is Jamie and Partner 2 is Julie. GitHub is displaying the line that Julie wrote and the line Jamie wrote separated by =======. So these are the two choices that Partner 2 has to decide between, which one do you want to keep? Where where does this decision start and end? The lines are bounded by &lt;&lt;&lt;&lt;&lt;&lt;&lt;HEAD and &gt;&gt;&gt;&gt;&gt;&gt;&gt;long commit identifier. So, to resolve this merge conflict, Partner 2 has to chose, and delete everything except the line they want. So, they will delete the &lt;&lt;&lt;&lt;&lt;&lt;HEAD, =====, &gt;&gt;&gt;&gt;long commit identifier and one of the lines that they don’t want to keep. Do that, and let’s try again. In this example, we’ve kept Jamie’s line: Then be sure to stage, and write a commit message. I often write “resolving merge conflict” or something so I know what I was up to. When I stage the file, notice how now my edits look like a simple line replacement (compare with the image above before it was re-staged): 9.9.1 Your turn Create a merge conflict with your partner, like we did in the example above. And try other ways to get and solve merge conflicts. For example, when you get the following error message, try both ways (commit or stash. Stash means copy/move it somewhere else, for example, on your Desktop temporarily). 9.10 How do you avoid merge conflicts? I’d say pull often, commit and sync often. Also, talk with your collaborators. Although our Ocean Health Index project is highly collaborative, we are actually rarely working on the exact same file at any given time. And if we are, we are also on Slack, Gchat, or sitting next to the person. But merge conflicts will occur and some of them will be heartbreaking and demoralizing. They happen to me when I collaborate with myself between my work computer and laptop. So protect yourself by pulling and syncing often! 9.11 Create your collaborative website OK. Let’s have Partner 2 create a new RMarkdown file. Here’s what they will do: Pull! Create a new RMarkdown file and name it index.Rmd. Make sure it’s all lowercase, and named index.Rmd. This will be the homepage for our website! Maybe change the title inside the Rmd, call it “Our website” Knit! Save and sync your .Rmd and your .html files (pull, stage, commit, pull, push) Go to GitHub.com and go to your rendered website! Where is it? Figure out your website’s url from your github repo’s url. For example: my github repo: https://github.com/jules32/collab-research my website url: https://jules32.github.io/collab-research/ note that the url starts with my username.github.io So cool! On websites, if something is called index.html, that defaults to the home page. So https://jules32.github.io/collab-research/ is the same as https://jules32.github.io/collab-research/index.html. If you name your RMarkdown file my_research.Rmd, the url will become https://jules32.github.io/collab-research/my_research.html. 9.12 Your turn Here is some collaborative analysis you can do on your own. We’ll be playing around with airline flights data, so let’s get setup a bit. Person 1: clean up the README to say something about you two, the authors. Person 2: edit the index.Rmd or create a new RMarkdown file: maybe add something about the authors, and knit it. Both of you: sync to GitHub.com (pull, stage, commit, push). Both of you: once you’ve both synced (talk to each other about it!), pull again. You should see each others’ work on your computer. Person 1: in the RMarkdown file, add a bit of the plan. We’ll be exploring the nycflights13 dataset. This is data on flights departing New York City in 2013. Person 2: in the README, add a bit of the plan. Both of you: sync 9.13 Explore on GitHub.com Now, let’s look at the repo again on GitHub.com. You’ll see those new files appear, and the commit history has increased. 9.13.1 Commit History You’ll see that the number of commits for the repo has increased, let’s have a look. You can see the history of both of you. 9.13.2 Blame Now let’s look at a single file, starting with the README file. We’ve explored the “Raw” and “History” options in the top-right of the file, but we haven’t really explored the “Blame” option. Let’s look now. Blame shows you line-by-line who authored the most recent version of the file you see. This is super useful if you’re trying to understand logic; you know who to ask for questions or attribute credit. 9.13.3 Issues Now let’s have a look at issues. This is a way you can communicate to others about plans for the repo, questions, etc. Note that issues are public if the repository is public. Let’s create a new issue with the title “NYC flights”. In the text box, let’s write a note to our collaborator. You can use Markdown in this text box, which means all of your header and bullet formatting will come through. You can also select these options by clicking them just above the text box. Let’s have one of you write something here. I’m going to write: Hi @jafflerbach! # first priority - explore NYC flights - plot interesting things Note that I have my collaborator’s GitHub name with a @ symbol. This is going to email her directly so that she sees this issue. I can click the “Preview” button at the top left of the text box to see how this will look rendered in Markdown. It looks good! Now let’s click submit new issue. On the right side, there are a bunch of options for categorizing and organizing your issues. You and your collaborator may want to make some labels and timelines, depending on the project. Another feature about issues is whether you want any notifications to this repository. Click where it says “Unwatch” up at the top. You’ll see three options: “Not watching”, “Watching”, and “Ignoring”. By default, you are watching these issues because you are a collaborator to the repository. But if you stop being a big contributor to this project, you may want to switch to “Not watching”. Or, you may want to ask an outside person to watch the issues. Or you may want to watch another repo yourself! Let’s have Person 2 respond to the issue affirming the plan. 9.14 NYC flights exploration Let’s continue this workflow with your collaborator, syncing to GitHub often and practicing what we’ve learned so far. We will get started together and then you and your collaborator will work on your own. Here’s what we’ll be doing (from R for Data Science’s Transform Chapter): Data: You will be exploring a dataset on flights departing New York City in 2013. These data are actually in a package called nycflights13, so we can load them the way we would any other package. Let’s have Person 1 write this in the RMarkdown document (Person 2 just listen for a moment; we will sync this to you in a moment). library(nycflights13) # install.packages(&#39;nycflights13&#39;) library(tidyverse) This data frame contains all 336,776 flights that departed from New York City in 2013. The data comes from the US Bureau of Transportation Statistics, and is documented in ?flights. flights ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # … with 336,766 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; Let’s select all flights on January 1st with: filter(flights, month == 1, day == 1) ## # A tibble: 842 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # … with 832 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; To use filtering effectively, you have to know how to select the observations that you want using the comparison operators. R provides the standard suite: &gt;, &gt;=, &lt;, &lt;=, != (not equal), and == (equal). We learned these operations yesterday. But there are a few others to learn as well. 9.14.0.1 Sync Sync this RMarkdown back to GitHub so that your collaborator has access to all these notes. Person 2 should then pull and will continue with the following notes: 9.14.1 Logical operators Multiple arguments to filter() are combined with “and”: every expression must be true in order for a row to be included in the output. For other types of combinations, you’ll need to use Boolean operators yourself: &amp; is “and” | is “or” ! is “not” Let’s have a look: The following code finds all flights that departed in November or December: filter(flights, month == 11 | month == 12) The order of operations doesn’t work like English. You can’t write filter(flights, month == 11 | 12), which you might literally translate into “finds all flights that departed in November or December”. Instead it finds all months that equal 11 | 12, an expression that evaluates to TRUE. In a numeric context (like here), TRUE becomes one, so this finds all flights in January, not November or December. This is quite confusing! A useful short-hand for this problem is x %in% y. This will select every row where x is one of the values in y. We could use it to rewrite the code above: nov_dec &lt;- filter(flights, month %in% c(11, 12)) Sometimes you can simplify complicated subsetting by remembering De Morgan’s law: !(x &amp; y) is the same as !x | !y, and !(x | y) is the same as !x &amp; !y. For example, if you wanted to find flights that weren’t delayed (on arrival or departure) by more than two hours, you could use either of the following two filters: filter(flights, !(arr_delay &gt; 120 | dep_delay &gt; 120)) filter(flights, arr_delay &lt;= 120, dep_delay &lt;= 120) Whenever you start using complicated, multipart expressions in filter(), consider making them explicit variables instead. That makes it much easier to check your work. 9.15 Your turn OK: Person 2, sync this to GitHub, and Person 1 will pull so that we all have the most current information. With your partner, do the following tasks. Each of you should work on one task at a time. Since we’re working closely on the same document, talk to each other and have one person create a heading and a R chunk, and then sync; the other person can then create a heading and R chunk and sync, and then you can both work safely. Remember to make your commit messages useful! As you work, you may get merge conflicts. This is part of collaborating in GitHub; we will walk through and help you with these and also teach the whole group. 9.15.1 Use logicals Find all flights that: Had an arrival delay of two or more hours Flew to Houston (IAH or HOU) Were operated by United, American, or Delta Departed in summer (July, August, and September) Arrived more than two hours late, but didn’t leave late Were delayed by at least an hour, but made up over 30 minutes in flight Departed between midnight and 6am (inclusive) Another useful dplyr filtering helper is between(). What does it do? Can you use it to simplify the code needed to answer the previous challenges? 9.15.2 Missing values To answer these questions: read some background below. How many flights have a missing dep_time? What other variables are missing? What might these rows represent? Why is NA ^ 0 not missing? Why is NA | TRUE not missing? Why is FALSE &amp; NA not missing? Can you figure out the general rule? (NA * 0 is a tricky counterexample!) One important feature of R that can make comparison tricky are missing values, or NAs (“not availables”). NA represents an unknown value so missing values are “contagious”: almost any operation involving an unknown value will also be unknown. NA &gt; 5 ## [1] NA 10 == NA ## [1] NA NA + 10 ## [1] NA NA / 2 ## [1] NA The most confusing result is this one: NA == NA ## [1] NA It’s easiest to understand why this is true with a bit more context: # Let x be Mary&#39;s age. We don&#39;t know how old she is. x &lt;- NA # Let y be John&#39;s age. We don&#39;t know how old he is. y &lt;- NA # Are John and Mary the same age? x == y ## [1] NA # We don&#39;t know! If you want to determine if a value is missing, use is.na(): is.na(x) ## [1] TRUE "],
["champion.html", "Chapter 10 Be a champion for open science 10.1 Objectives and Resources 10.2 Three messages 10.3 Build community", " Chapter 10 Be a champion for open science in development… 10.1 Objectives and Resources To provide resources for you to promote good practices for open and reproducible science in your communities and institutions. 10.2 Three messages If there are 3 things to communicate to others after this workshop, I think they would be: 1. Data science is a discipline that can improve your analyses There are concepts, theory, and tools for thinking about and working with data. Your study system is not unique when it comes to data, and accepting this will speed up your analyses. This helps your science: Think deliberately about data: when you distinguish data questions from research questions, you’ll learn how and who to ask for help Save heartache: you don’t have to reinvent the wheel Save time: when you expect there’s a better way to do what you are doing, you’ll find the solution faster. Focus on the science. 2. Open data science tools exist Data science tools that enable open science are game-changing for analysis, collaboration and communication. Open science is “the concept of transparency at all stages of the research process, coupled with free and open access to data, code, and papers” (Hampton et al. 2015)) This helps your science: Have confidence in your analyses from this traceable, reusable record Save time through automation, thinking ahead of your immediate task, reduced bookkeeping, and collaboration Take advantage of convenient access: working openly online is like having an extended memory 3. Learn these tools with collaborators and community (redefined): Your most important collaborator is Future You. Community should also be beyond the colleagues in your field. Learn from, with, and for others. This helps your science: If you learn to talk about your data, you’ll find solutions faster. Build confidence: these skills are transferable beyond your science. Be empathetic and inclusive and build a network of allies 10.3 Build community Join existing communities locally and online, and start local chapters with friends! Some ideas: Mozilla Study Groups Example: Eco-data-science. Also see (Steven et al. 2018) RLadies. Example: RLadies Santa Barbara These meetups can be for skill-sharing, showcasing how people work, or building community so you can troubleshoot together. They can be an informal “hacky hour” at a cafe or pub! "]
]
